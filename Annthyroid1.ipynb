{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.197324</td>\n",
       "      <td>0.300926</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.239583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.164345</td>\n",
       "      <td>0.235786</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.165625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.479167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.167224</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.091922</td>\n",
       "      <td>0.125418</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.129688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.142061</td>\n",
       "      <td>0.229097</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.235938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7085</th>\n",
       "      <td>0.604167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.113092</td>\n",
       "      <td>0.128763</td>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.030641</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7087</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.147157</td>\n",
       "      <td>0.231481</td>\n",
       "      <td>0.206250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7088</th>\n",
       "      <td>0.354167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.147157</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.154688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7089</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.132107</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7090 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0   1   2   3   4   5   6   7   8   9   ...  12  13  14  15  \\\n",
       "0     0.750000   1   0   1   1   1   1   1   0   1  ...   1   1   1   1   \n",
       "1     0.239583   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "2     0.479167   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "3     0.656250   0   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "4     0.229167   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "...        ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..   \n",
       "7085  0.604167   1   1   1   1   1   1   1   1   1  ...   1   1   1   0   \n",
       "7086  0.520833   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "7087  0.520833   1   1   1   1   1   1   1   1   1  ...   1   1   1   0   \n",
       "7088  0.354167   0   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "7089  0.750000   1   1   1   1   1   1   1   1   1  ...   1   1   1   0   \n",
       "\n",
       "            16        17        18        19        20  21  \n",
       "0     0.001132  0.080780  0.197324  0.300926  0.225000   1  \n",
       "1     0.000472  0.164345  0.235786  0.537037  0.165625   1  \n",
       "2     0.003585  0.130919  0.167224  0.527778  0.118750   1  \n",
       "3     0.001698  0.091922  0.125418  0.337963  0.129688   1  \n",
       "4     0.000472  0.142061  0.229097  0.337963  0.235938   1  \n",
       "...        ...       ...       ...       ...       ...  ..  \n",
       "7085  0.004717  0.113092  0.128763  0.379630  0.121875   1  \n",
       "7086  0.200000  0.030641  0.005017  0.333333  0.005469  -1  \n",
       "7087  0.001434  0.109192  0.147157  0.231481  0.206250   1  \n",
       "7088  0.005283  0.109192  0.147157  0.333333  0.154688   1  \n",
       "7089  0.001057  0.109192  0.132107  0.337963  0.137500   1  \n",
       "\n",
       "[7090 rows x 22 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_raw = pd.read_csv(\"wdbc.csv\", header=None)\n",
    "df_raw = pd.read_csv(\"./annthyroid.csv\", header=None)\n",
    "\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rongavilla\\AppData\\Local\\Temp\\ipykernel_19400\\46608714.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw[21].loc[df_raw[21] == -1] = 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.197324</td>\n",
       "      <td>0.300926</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.239583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.164345</td>\n",
       "      <td>0.235786</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.165625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.479167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.167224</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.091922</td>\n",
       "      <td>0.125418</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.129688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.142061</td>\n",
       "      <td>0.229097</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.235938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7085</th>\n",
       "      <td>0.604167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.113092</td>\n",
       "      <td>0.128763</td>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.030641</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7087</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.147157</td>\n",
       "      <td>0.231481</td>\n",
       "      <td>0.206250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7088</th>\n",
       "      <td>0.354167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.147157</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.154688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7089</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.132107</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7090 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0   1   2   3   4   5   6   7   8   9   ...  12  13  14  15  \\\n",
       "0     0.750000   1   0   1   1   1   1   1   0   1  ...   1   1   1   1   \n",
       "1     0.239583   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "2     0.479167   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "3     0.656250   0   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "4     0.229167   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "...        ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..   \n",
       "7085  0.604167   1   1   1   1   1   1   1   1   1  ...   1   1   1   0   \n",
       "7086  0.520833   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "7087  0.520833   1   1   1   1   1   1   1   1   1  ...   1   1   1   0   \n",
       "7088  0.354167   0   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "7089  0.750000   1   1   1   1   1   1   1   1   1  ...   1   1   1   0   \n",
       "\n",
       "            16        17        18        19        20  21  \n",
       "0     0.001132  0.080780  0.197324  0.300926  0.225000   1  \n",
       "1     0.000472  0.164345  0.235786  0.537037  0.165625   1  \n",
       "2     0.003585  0.130919  0.167224  0.527778  0.118750   1  \n",
       "3     0.001698  0.091922  0.125418  0.337963  0.129688   1  \n",
       "4     0.000472  0.142061  0.229097  0.337963  0.235938   1  \n",
       "...        ...       ...       ...       ...       ...  ..  \n",
       "7085  0.004717  0.113092  0.128763  0.379630  0.121875   1  \n",
       "7086  0.200000  0.030641  0.005017  0.333333  0.005469   0  \n",
       "7087  0.001434  0.109192  0.147157  0.231481  0.206250   1  \n",
       "7088  0.005283  0.109192  0.147157  0.333333  0.154688   1  \n",
       "7089  0.001057  0.109192  0.132107  0.337963  0.137500   1  \n",
       "\n",
       "[7090 rows x 22 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw[21].loc[df_raw[21] == -1] = 0\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "7085    1\n",
       "7086    0\n",
       "7087    1\n",
       "7088    1\n",
       "7089    1\n",
       "Name: 21, Length: 7090, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(df_raw[21])\n",
    "y = df_raw[21]\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.197324</td>\n",
       "      <td>0.300926</td>\n",
       "      <td>0.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.239583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.164345</td>\n",
       "      <td>0.235786</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.165625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.479167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.167224</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.118750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.091922</td>\n",
       "      <td>0.125418</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.129688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.142061</td>\n",
       "      <td>0.229097</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.235938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9   ...   11   12   13  \\\n",
       "0  0.750000  1.0  0.0  1.0  1.0  1.0  1.0  1.0  0.0  1.0  ...  1.0  1.0  1.0   \n",
       "1  0.239583  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "2  0.479167  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "3  0.656250  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "4  0.229167  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "\n",
       "    14   15        16        17        18        19        20  \n",
       "0  1.0  1.0  0.001132  0.080780  0.197324  0.300926  0.225000  \n",
       "1  1.0  1.0  0.000472  0.164345  0.235786  0.537037  0.165625  \n",
       "2  1.0  1.0  0.003585  0.130919  0.167224  0.527778  0.118750  \n",
       "3  1.0  1.0  0.001698  0.091922  0.125418  0.337963  0.129688  \n",
       "4  1.0  1.0  0.000472  0.142061  0.229097  0.337963  0.235938  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_raw.iloc[:,:-1]\n",
    "x = (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "x.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw, x_test, y_raw, y_test = train_test_split(x, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of 0 in the training set is: 428\n",
      "The number of 1 in the training set is: 5244\n",
      "Goal: Generate 4816 datasets for 0.\n"
     ]
    }
   ],
   "source": [
    "# zero_count = y_raw[0][y_raw[0] == 1].count()\n",
    "# one_count = y_raw[1][y_raw[1] == 1].count()\n",
    "# zero_count = y_raw[y_raw[0] == 0].count()\n",
    "# one_count = y_raw[0][y_raw[0] == 1].count()\n",
    "\n",
    "zero_count = 0\n",
    "one_count = 0\n",
    "for i in y_raw:\n",
    "    if i == 0:\n",
    "        zero_count += 1\n",
    "    else:\n",
    "        one_count += 1\n",
    "\n",
    "print('The number of 0 in the training set is: {}'.format(zero_count))\n",
    "print('The number of 1 in the training set is: {}'.format(one_count))\n",
    "\n",
    "to_generate = one_count-zero_count\n",
    "print('Goal: Generate {} datasets for 0.'.format(to_generate))\n",
    "\n",
    "# to_generate = 4816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.108635</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.146875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020925</td>\n",
       "      <td>0.069638</td>\n",
       "      <td>0.143813</td>\n",
       "      <td>0.402778</td>\n",
       "      <td>0.126563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>0.489583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.137736</td>\n",
       "      <td>0.125348</td>\n",
       "      <td>0.142140</td>\n",
       "      <td>0.439815</td>\n",
       "      <td>0.118750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>0.281250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.194340</td>\n",
       "      <td>0.113092</td>\n",
       "      <td>0.105351</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.084375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>0.843750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011698</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.162207</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.168750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3453</th>\n",
       "      <td>0.510417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014340</td>\n",
       "      <td>0.091922</td>\n",
       "      <td>0.210702</td>\n",
       "      <td>0.421296</td>\n",
       "      <td>0.181250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611</th>\n",
       "      <td>0.791667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.266038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.402778</td>\n",
       "      <td>0.001563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.052925</td>\n",
       "      <td>0.137124</td>\n",
       "      <td>0.564815</td>\n",
       "      <td>0.090625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>0.635417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020755</td>\n",
       "      <td>0.052925</td>\n",
       "      <td>0.165552</td>\n",
       "      <td>0.287037</td>\n",
       "      <td>0.196875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>0.645833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014528</td>\n",
       "      <td>0.103064</td>\n",
       "      <td>0.145485</td>\n",
       "      <td>0.402778</td>\n",
       "      <td>0.129688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1    2    3    4    5    6    7    8    9   ...   11   12  \\\n",
       "5398  0.750000  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "2900  0.708333  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "5002  0.489583  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "2827  0.281250  1.0  1.0  1.0  1.0  1.0  1.0  0.0  1.0  1.0  ...  1.0  1.0   \n",
       "4652  0.843750  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "3453  0.510417  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "4611  0.791667  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "728   0.750000  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "3049  0.635417  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "2962  0.645833  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "\n",
       "       13   14   15        16        17        18        19        20  \n",
       "5398  1.0  1.0  1.0  0.028302  0.108635  0.130435  0.305556  0.146875  \n",
       "2900  1.0  1.0  1.0  0.020925  0.069638  0.143813  0.402778  0.126563  \n",
       "5002  1.0  1.0  1.0  0.137736  0.125348  0.142140  0.439815  0.118750  \n",
       "2827  1.0  1.0  1.0  0.194340  0.113092  0.105351  0.458333  0.084375  \n",
       "4652  1.0  1.0  1.0  0.011698  0.080780  0.162207  0.337963  0.168750  \n",
       "...   ...  ...  ...       ...       ...       ...       ...       ...  \n",
       "3453  1.0  1.0  1.0  0.014340  0.091922  0.210702  0.421296  0.181250  \n",
       "4611  1.0  1.0  1.0  0.266038  0.000000  0.001672  0.402778  0.001563  \n",
       "728   1.0  1.0  1.0  0.018868  0.052925  0.137124  0.564815  0.090625  \n",
       "3049  1.0  1.0  0.0  0.020755  0.052925  0.165552  0.287037  0.196875  \n",
       "2962  1.0  1.0  1.0  0.014528  0.103064  0.145485  0.402778  0.129688  \n",
       "\n",
       "[428 rows x 21 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_missing = x_raw[y_raw.values == 0]\n",
    "x_missing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, num_features=8, num_dim=21):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        \n",
    "        self.num_features = num_features\n",
    "        self.num_dim = num_dim\n",
    "        \n",
    "        self.encoder_layer_1 = nn.Linear(in_features=self.num_dim, out_features=14)\n",
    "        self.encoder_layer_2 = nn.Linear(in_features=14, out_features=(self.num_features * 2))\n",
    "        \n",
    "        self.decoder_layer_1 = nn.Linear(in_features=self.num_features, out_features=14)\n",
    "        self.decoder_layer_2 = nn.Linear(in_features=14, out_features=self.num_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU() # hidden layers\n",
    "        self.sigmoid = nn.Sigmoid() # output layer\n",
    "        \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        :param mu: mean from the encoder's latent space\n",
    "        :param log_var: log variance from the encoder's latent space\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5*log_var) # standard deviation\n",
    "        eps = torch.randn_like(std)  # `randn_like` as we need the same size\n",
    "        sample = mu + (eps * std)    # sampling as if coming from the input space\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def encode(self, x):\n",
    "        # encoding\n",
    "        #x = F.relu(self.encoder_layer_1(x))\n",
    "        x = self.encoder_layer_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.encoder_layer_2(x).view(-1, 2, self.num_features)\n",
    "        \n",
    "        # get `mu` and `log_var`\n",
    "        mu = x[:, 0, :] # the first feature values as mean\n",
    "        log_var = x[:, 1, :] # the other feature values as variance\n",
    "        \n",
    "        # get the latent vector through reparameterization\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        \n",
    "        return z, mu, log_var\n",
    "    \n",
    "    def decode(self, z, mu, log_var):\n",
    "        # decoding\n",
    "        #x = F.relu(self.decoder_layer_1(z))\n",
    "        x = self.decoder_layer_1(z)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        #reconstruction = torch.sigmoid(self.decoder_layer_2(x))\n",
    "        reconstruction = self.decoder_layer_2(x)\n",
    "        reconstruction = self.sigmoid(reconstruction)\n",
    "        \n",
    "        return reconstruction, mu, log_var\n",
    "    \n",
    "    # Utility function to generate new data based on:\n",
    "    # mu: The average that you want to have (should be the same size as num_features)\n",
    "    # log_var: The variance that you want to have (should be the same size as num_features)\n",
    "    def sample(self, mu, log_var):\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        reconstruction, mu, log_var = self.decode(z, mu, log_var)\n",
    "        \n",
    "        return reconstruction\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        z, mu, log_var = self.encode(x)\n",
    "        reconstruction, mu, log_var = self.decode(z, mu, log_var)\n",
    "        \n",
    "        return reconstruction, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset to treat how the model picks an x, y combination from the dataset\n",
    "class AutoencoderDataset(Dataset):\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    # Requires you to return data as a pair of _x, _y\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.x[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final loss is a combination of the reconstruction loss (first argument) and the loss from an assumed distribution (i.e. Normal / Gaussian distribution)\n",
    "def final_loss(bce_loss, mu, logvar):\n",
    "    \"\"\"\n",
    "    This function will add the reconstruction loss (BCELoss) and the \n",
    "    KL-Divergence.\n",
    "    KL-Divergence = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    :param bce_loss: recontruction loss\n",
    "    :param mu: the mean from the latent vector\n",
    "    :param logvar: log variance from the latent vector\n",
    "    \"\"\"\n",
    "    BCE = bce_loss \n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 8\n",
    "model = VariationalAutoencoder(num_features=num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn, batch_size):\n",
    "    loop = tqdm(loader)\n",
    "    \n",
    "    count = 0\n",
    "    ave_loss = 0.00\n",
    "    \n",
    "    # Loop per batch\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        reconstruction, mu, logvar = model.forward(data)\n",
    "        \n",
    "        loss = loss_fn(reconstruction, targets)\n",
    "        \n",
    "        loss = final_loss(loss, mu, logvar)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "        ave_loss += loss.item()\n",
    "        count += 1\n",
    "        \n",
    "    ave_loss = ave_loss / count\n",
    "    \n",
    "    return ave_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_missing = torch.Tensor(np.array(x_missing))\n",
    "\n",
    "# use Dataloader for Autoencoder \n",
    "custom_dataset = AutoencoderDataset(x_missing)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    custom_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 288.81it/s, loss=1.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 2.6269277639167252\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 378.79it/s, loss=1.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 1.6148498501888542\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 328.44it/s, loss=0.825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 1.1043151111103768\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 333.52it/s, loss=0.789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.8783505856990814\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 267.27it/s, loss=0.742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.7878421080666919\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 282.75it/s, loss=0.711]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.7479311359483142\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 291.92it/s, loss=0.704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.723216456036235\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 312.33it/s, loss=0.685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.7074790021707845\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 314.06it/s, loss=0.669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.6919697467670884\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 325.96it/s, loss=0.664]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.6759195161420245\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 390.10it/s, loss=0.656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.661689241958219\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 413.47it/s, loss=0.63] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.6480640207612237\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 382.29it/s, loss=0.63] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.6331979611585307\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 294.37it/s, loss=0.621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.6184400437876235\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 358.38it/s, loss=0.599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.6036190716333167\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 397.74it/s, loss=0.591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.5893984229065651\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 373.55it/s, loss=0.587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.5739865601062775\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 392.73it/s, loss=0.571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.5611646404100019\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 391.88it/s, loss=0.506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.5415033413920292\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 244.08it/s, loss=0.499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.528301905407462\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 258.12it/s, loss=0.559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.5179466851228891\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 296.60it/s, loss=0.526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.5078421051419059\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 298.31it/s, loss=0.493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.48710780261560926\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 266.50it/s, loss=0.495]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.473893532226252\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 305.72it/s, loss=0.444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.46381485496842584\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 316.38it/s, loss=0.483]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.44680596853411475\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 313.86it/s, loss=0.431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.43886584771233933\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 326.84it/s, loss=0.428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.42832210694634637\n",
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 317.67it/s, loss=0.449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.4153942711824595\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 318.59it/s, loss=0.437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.4037630266921465\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 396.57it/s, loss=0.476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.3946594252835873\n",
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 392.27it/s, loss=0.384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.38303351402282715\n",
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 406.54it/s, loss=0.379]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.3733809881432112\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 405.65it/s, loss=0.379]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.3647572491751161\n",
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 407.05it/s, loss=0.39] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.3622505266306012\n",
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 399.80it/s, loss=0.34] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.35398068331008736\n",
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 312.56it/s, loss=0.388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.34320628469766573\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 302.67it/s, loss=0.342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.3324968211872633\n",
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 288.90it/s, loss=0.37] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.32932666152022605\n",
      "Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 323.20it/s, loss=0.339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.32558005216509794\n",
      "Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 315.88it/s, loss=0.322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.31214074929093205\n",
      "Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 291.19it/s, loss=0.344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.3125605037392572\n",
      "Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 307.96it/s, loss=0.33] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.30446883256352225\n",
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 327.74it/s, loss=0.349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.30050660288611125\n",
      "Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 289.47it/s, loss=0.349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.29446317636689473\n",
      "Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 346.53it/s, loss=0.296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2937567161266194\n",
      "Epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 354.41it/s, loss=0.326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.28439775421175845\n",
      "Epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 334.89it/s, loss=0.318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2819635850745578\n",
      "Epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 374.65it/s, loss=0.294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2803960378433383\n",
      "Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 397.65it/s, loss=0.305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2761813792031865\n",
      "Epoch: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 315.58it/s, loss=0.291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.27428965686365614\n",
      "Epoch: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 393.07it/s, loss=0.344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2703982395834701\n",
      "Epoch: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 388.62it/s, loss=0.308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2654155530901842\n",
      "Epoch: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 397.80it/s, loss=0.299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2640221482792566\n",
      "Epoch: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 364.42it/s, loss=0.329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2618794189982636\n",
      "Epoch: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 383.89it/s, loss=0.301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.25904357034799663\n",
      "Epoch: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 365.11it/s, loss=0.279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.26023500239433245\n",
      "Epoch: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 389.68it/s, loss=0.275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.25476854658404063\n",
      "Epoch: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 432.46it/s, loss=0.267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.25442138002362363\n",
      "Epoch: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 412.18it/s, loss=0.277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2517143572832263\n",
      "Epoch: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 398.34it/s, loss=0.284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.25008582219828007\n",
      "Epoch: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 417.80it/s, loss=0.281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.24851469089125477\n",
      "Epoch: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 404.68it/s, loss=0.282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.24826520421477252\n",
      "Epoch: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 374.17it/s, loss=0.279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.24653039162242135\n",
      "Epoch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 386.43it/s, loss=0.261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.24536157676646875\n",
      "Epoch: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 403.08it/s, loss=0.276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.24281140953995461\n",
      "Epoch: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 407.58it/s, loss=0.279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2427527327523675\n",
      "Epoch: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 412.52it/s, loss=0.291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23927506146042846\n",
      "Epoch: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 435.53it/s, loss=0.286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23881346333858577\n",
      "Epoch: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 369.22it/s, loss=0.286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23969624572715095\n",
      "Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 374.93it/s, loss=0.275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23767794131539588\n",
      "Epoch: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 407.47it/s, loss=0.26] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23835376320883286\n",
      "Epoch: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 407.34it/s, loss=0.261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23717444892539535\n",
      "Epoch: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 418.58it/s, loss=0.278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23672672915597295\n",
      "Epoch: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 326.62it/s, loss=0.321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23637773858946423\n",
      "Epoch: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 350.88it/s, loss=0.263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23456762696421424\n",
      "Epoch: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 375.65it/s, loss=0.277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23390690237283707\n",
      "Epoch: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 384.84it/s, loss=0.252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23365339896706647\n",
      "Epoch: 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 374.78it/s, loss=0.249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2316414765840353\n",
      "Epoch: 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 416.10it/s, loss=0.304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2334536572181901\n",
      "Epoch: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 357.29it/s, loss=0.262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23239176633746125\n",
      "Epoch: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 385.98it/s, loss=0.256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23143265846856806\n",
      "Epoch: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 414.27it/s, loss=0.26] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23154796209446218\n",
      "Epoch: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 342.37it/s, loss=0.293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23141635434572086\n",
      "Epoch: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 331.95it/s, loss=0.257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2298275623903718\n",
      "Epoch: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 330.59it/s, loss=0.257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2295279400639756\n",
      "Epoch: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 387.87it/s, loss=0.264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22996666109146074\n",
      "Epoch: 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 391.39it/s, loss=0.264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22811883150838141\n",
      "Epoch: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 317.11it/s, loss=0.265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22884009137403133\n",
      "Epoch: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 399.56it/s, loss=0.258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2294096503146859\n",
      "Epoch: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 387.77it/s, loss=0.263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2298694280690925\n",
      "Epoch: 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 335.42it/s, loss=0.261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2293376153291658\n",
      "Epoch: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 318.36it/s, loss=0.266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2274788410164589\n",
      "Epoch: 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 397.45it/s, loss=0.259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2276319461159928\n",
      "Epoch: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 424.92it/s, loss=0.264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22697191148303275\n",
      "Epoch: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 405.37it/s, loss=0.27] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22720407313385674\n",
      "Epoch: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 435.83it/s, loss=0.257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2269589911366618\n",
      "Epoch: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 381.24it/s, loss=0.271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22696417691402657\n",
      "Epoch: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 374.51it/s, loss=0.276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22585788698390472\n",
      "Epoch: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 378.54it/s, loss=0.253]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22575159232283748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    \n",
    "    ave_loss = train_fn(\n",
    "        train_loader,\n",
    "        model,\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "        batch_size\n",
    "    )\n",
    "    \n",
    "    losses.append(ave_loss)\n",
    "    \n",
    "    print(\"Ave Loss: {}\".format(ave_loss))\n",
    "    \n",
    "    state = { 'state_dict': model.state_dict() }\n",
    "\n",
    "    torch.save(state, \"variational-autoencoder.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses, label='loss', color='red')\n",
    "plt.title('Training Evaluation', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Error Value', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vector of zero tensors representing 0 average per num_feature (right in the middle of the dist)\n",
    "sampled_mu = torch.Tensor([np.zeros(num_features)])\n",
    "\n",
    "# Create a vector of zero tensors representing 0 standard deviations away from the mean to create variations\n",
    "# Change this is you want to sample away from the mean to create \"off-quality\" data\n",
    "sampled_logvar = torch.Tensor([np.zeros(num_features)])\n",
    "\n",
    "sampled_logvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5288, 0.7781, 0.9739, 0.9784, 0.9970, 0.9393, 0.9953, 0.9866, 0.9855,\n",
       "         0.8883, 0.9426, 0.9882, 0.9908, 0.9778, 0.9967, 0.9903, 0.0587, 0.0915,\n",
       "         0.1143, 0.3514, 0.0875]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction = model.sample(sampled_mu, sampled_logvar)\n",
    "reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>0.510417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>0.108635</td>\n",
       "      <td>0.209030</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.173438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.108635</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.146875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>0.614583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.186104</td>\n",
       "      <td>0.365741</td>\n",
       "      <td>0.180875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6768</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.097493</td>\n",
       "      <td>0.147157</td>\n",
       "      <td>0.287037</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>0.385417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.111978</td>\n",
       "      <td>0.182575</td>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.171984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>0.572917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.111978</td>\n",
       "      <td>0.220736</td>\n",
       "      <td>0.398148</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>0.739583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.177258</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>0.385417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.175487</td>\n",
       "      <td>0.224080</td>\n",
       "      <td>0.342593</td>\n",
       "      <td>0.229688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.013928</td>\n",
       "      <td>0.050167</td>\n",
       "      <td>0.162037</td>\n",
       "      <td>0.090625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>0.614583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.142061</td>\n",
       "      <td>0.185619</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.193750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5672 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1    2    3    4    5    6    7    8    9   ...   11   12  \\\n",
       "2707  0.510417  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "5398  0.750000  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "4281  0.614583  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "6768  0.656250  1.0  0.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  ...  1.0  1.0   \n",
       "2836  0.385417  0.0  0.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  ...  1.0  1.0   \n",
       "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "905   0.572917  1.0  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "5192  0.739583  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "3980  0.385417  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "235   0.500000  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "5157  0.614583  1.0  1.0  1.0  1.0  1.0  1.0  0.0  1.0  1.0  ...  1.0  1.0   \n",
       "\n",
       "       13   14   15        16        17        18        19        20  \n",
       "2707  1.0  1.0  1.0  0.004340  0.108635  0.209030  0.444444  0.173438  \n",
       "5398  1.0  1.0  1.0  0.028302  0.108635  0.130435  0.305556  0.146875  \n",
       "4281  1.0  1.0  1.0  0.004377  0.109192  0.186104  0.365741  0.180875  \n",
       "6768  1.0  1.0  1.0  0.001057  0.097493  0.147157  0.287037  0.175000  \n",
       "2836  1.0  1.0  1.0  0.003566  0.111978  0.182575  0.379630  0.171984  \n",
       "...   ...  ...  ...       ...       ...       ...       ...       ...  \n",
       "905   1.0  1.0  1.0  0.000377  0.111978  0.220736  0.398148  0.200000  \n",
       "5192  1.0  1.0  0.0  0.002642  0.109192  0.177258  0.361111  0.175000  \n",
       "3980  1.0  1.0  1.0  0.002830  0.175487  0.224080  0.342593  0.229688  \n",
       "235   1.0  1.0  1.0  0.000189  0.013928  0.050167  0.162037  0.090625  \n",
       "5157  1.0  1.0  1.0  0.003208  0.142061  0.185619  0.337963  0.193750  \n",
       "\n",
       "[5672 rows x 21 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_fab = x_raw\n",
    "x_fab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.570820</td>\n",
       "      <td>0.756908</td>\n",
       "      <td>0.970703</td>\n",
       "      <td>0.966375</td>\n",
       "      <td>0.986433</td>\n",
       "      <td>0.950032</td>\n",
       "      <td>0.983663</td>\n",
       "      <td>0.982346</td>\n",
       "      <td>0.966417</td>\n",
       "      <td>0.807102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981075</td>\n",
       "      <td>0.991234</td>\n",
       "      <td>0.960881</td>\n",
       "      <td>0.988377</td>\n",
       "      <td>0.960505</td>\n",
       "      <td>0.092287</td>\n",
       "      <td>0.114152</td>\n",
       "      <td>0.168468</td>\n",
       "      <td>0.409107</td>\n",
       "      <td>0.143744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.535825</td>\n",
       "      <td>0.716823</td>\n",
       "      <td>0.978748</td>\n",
       "      <td>0.972951</td>\n",
       "      <td>0.996342</td>\n",
       "      <td>0.969727</td>\n",
       "      <td>0.995447</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.988026</td>\n",
       "      <td>0.855615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980910</td>\n",
       "      <td>0.994410</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.988496</td>\n",
       "      <td>0.976164</td>\n",
       "      <td>0.056008</td>\n",
       "      <td>0.071097</td>\n",
       "      <td>0.116925</td>\n",
       "      <td>0.378149</td>\n",
       "      <td>0.112388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.537340</td>\n",
       "      <td>0.807377</td>\n",
       "      <td>0.976980</td>\n",
       "      <td>0.992528</td>\n",
       "      <td>0.996526</td>\n",
       "      <td>0.981605</td>\n",
       "      <td>0.995618</td>\n",
       "      <td>0.991381</td>\n",
       "      <td>0.982453</td>\n",
       "      <td>0.877304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985793</td>\n",
       "      <td>0.997892</td>\n",
       "      <td>0.977843</td>\n",
       "      <td>0.994419</td>\n",
       "      <td>0.980125</td>\n",
       "      <td>0.058663</td>\n",
       "      <td>0.051483</td>\n",
       "      <td>0.101680</td>\n",
       "      <td>0.373908</td>\n",
       "      <td>0.107997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.560116</td>\n",
       "      <td>0.772653</td>\n",
       "      <td>0.971443</td>\n",
       "      <td>0.995614</td>\n",
       "      <td>0.993621</td>\n",
       "      <td>0.976368</td>\n",
       "      <td>0.997639</td>\n",
       "      <td>0.995676</td>\n",
       "      <td>0.990734</td>\n",
       "      <td>0.875341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972225</td>\n",
       "      <td>0.998109</td>\n",
       "      <td>0.968602</td>\n",
       "      <td>0.991526</td>\n",
       "      <td>0.978826</td>\n",
       "      <td>0.084490</td>\n",
       "      <td>0.064109</td>\n",
       "      <td>0.116397</td>\n",
       "      <td>0.364355</td>\n",
       "      <td>0.101338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.582208</td>\n",
       "      <td>0.878762</td>\n",
       "      <td>0.987820</td>\n",
       "      <td>0.987775</td>\n",
       "      <td>0.996654</td>\n",
       "      <td>0.972727</td>\n",
       "      <td>0.996863</td>\n",
       "      <td>0.993521</td>\n",
       "      <td>0.988827</td>\n",
       "      <td>0.916892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993949</td>\n",
       "      <td>0.996282</td>\n",
       "      <td>0.983202</td>\n",
       "      <td>0.998567</td>\n",
       "      <td>0.995130</td>\n",
       "      <td>0.059962</td>\n",
       "      <td>0.052580</td>\n",
       "      <td>0.108792</td>\n",
       "      <td>0.358121</td>\n",
       "      <td>0.064819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>0.523773</td>\n",
       "      <td>0.846847</td>\n",
       "      <td>0.979460</td>\n",
       "      <td>0.989623</td>\n",
       "      <td>0.997662</td>\n",
       "      <td>0.949566</td>\n",
       "      <td>0.995882</td>\n",
       "      <td>0.990173</td>\n",
       "      <td>0.986897</td>\n",
       "      <td>0.891207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994618</td>\n",
       "      <td>0.996475</td>\n",
       "      <td>0.982644</td>\n",
       "      <td>0.998834</td>\n",
       "      <td>0.993999</td>\n",
       "      <td>0.069935</td>\n",
       "      <td>0.077047</td>\n",
       "      <td>0.111534</td>\n",
       "      <td>0.378788</td>\n",
       "      <td>0.069410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4812</th>\n",
       "      <td>0.557456</td>\n",
       "      <td>0.743915</td>\n",
       "      <td>0.937826</td>\n",
       "      <td>0.965978</td>\n",
       "      <td>0.988429</td>\n",
       "      <td>0.941798</td>\n",
       "      <td>0.983637</td>\n",
       "      <td>0.975114</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.817158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958344</td>\n",
       "      <td>0.982414</td>\n",
       "      <td>0.947885</td>\n",
       "      <td>0.976669</td>\n",
       "      <td>0.960906</td>\n",
       "      <td>0.073398</td>\n",
       "      <td>0.080276</td>\n",
       "      <td>0.164737</td>\n",
       "      <td>0.393641</td>\n",
       "      <td>0.182968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>0.577125</td>\n",
       "      <td>0.796695</td>\n",
       "      <td>0.986075</td>\n",
       "      <td>0.975226</td>\n",
       "      <td>0.997112</td>\n",
       "      <td>0.948879</td>\n",
       "      <td>0.996345</td>\n",
       "      <td>0.986985</td>\n",
       "      <td>0.991717</td>\n",
       "      <td>0.865844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986945</td>\n",
       "      <td>0.988619</td>\n",
       "      <td>0.980466</td>\n",
       "      <td>0.994478</td>\n",
       "      <td>0.989071</td>\n",
       "      <td>0.048237</td>\n",
       "      <td>0.063770</td>\n",
       "      <td>0.101559</td>\n",
       "      <td>0.368176</td>\n",
       "      <td>0.081754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>0.580795</td>\n",
       "      <td>0.759357</td>\n",
       "      <td>0.977377</td>\n",
       "      <td>0.944699</td>\n",
       "      <td>0.989590</td>\n",
       "      <td>0.952826</td>\n",
       "      <td>0.980197</td>\n",
       "      <td>0.986556</td>\n",
       "      <td>0.975401</td>\n",
       "      <td>0.798458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984730</td>\n",
       "      <td>0.986013</td>\n",
       "      <td>0.977325</td>\n",
       "      <td>0.987388</td>\n",
       "      <td>0.953415</td>\n",
       "      <td>0.052079</td>\n",
       "      <td>0.097728</td>\n",
       "      <td>0.134255</td>\n",
       "      <td>0.399315</td>\n",
       "      <td>0.131385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>0.565848</td>\n",
       "      <td>0.761814</td>\n",
       "      <td>0.947968</td>\n",
       "      <td>0.982503</td>\n",
       "      <td>0.987962</td>\n",
       "      <td>0.961639</td>\n",
       "      <td>0.988355</td>\n",
       "      <td>0.972904</td>\n",
       "      <td>0.966672</td>\n",
       "      <td>0.825539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956058</td>\n",
       "      <td>0.984031</td>\n",
       "      <td>0.958849</td>\n",
       "      <td>0.977012</td>\n",
       "      <td>0.965487</td>\n",
       "      <td>0.078335</td>\n",
       "      <td>0.086431</td>\n",
       "      <td>0.136381</td>\n",
       "      <td>0.396775</td>\n",
       "      <td>0.157406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4816 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.570820  0.756908  0.970703  0.966375  0.986433  0.950032  0.983663   \n",
       "1     0.535825  0.716823  0.978748  0.972951  0.996342  0.969727  0.995447   \n",
       "2     0.537340  0.807377  0.976980  0.992528  0.996526  0.981605  0.995618   \n",
       "3     0.560116  0.772653  0.971443  0.995614  0.993621  0.976368  0.997639   \n",
       "4     0.582208  0.878762  0.987820  0.987775  0.996654  0.972727  0.996863   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4811  0.523773  0.846847  0.979460  0.989623  0.997662  0.949566  0.995882   \n",
       "4812  0.557456  0.743915  0.937826  0.965978  0.988429  0.941798  0.983637   \n",
       "4813  0.577125  0.796695  0.986075  0.975226  0.997112  0.948879  0.996345   \n",
       "4814  0.580795  0.759357  0.977377  0.944699  0.989590  0.952826  0.980197   \n",
       "4815  0.565848  0.761814  0.947968  0.982503  0.987962  0.961639  0.988355   \n",
       "\n",
       "            7         8         9   ...        11        12        13  \\\n",
       "0     0.982346  0.966417  0.807102  ...  0.981075  0.991234  0.960881   \n",
       "1     0.991241  0.988026  0.855615  ...  0.980910  0.994410  0.968000   \n",
       "2     0.991381  0.982453  0.877304  ...  0.985793  0.997892  0.977843   \n",
       "3     0.995676  0.990734  0.875341  ...  0.972225  0.998109  0.968602   \n",
       "4     0.993521  0.988827  0.916892  ...  0.993949  0.996282  0.983202   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4811  0.990173  0.986897  0.891207  ...  0.994618  0.996475  0.982644   \n",
       "4812  0.975114  0.965385  0.817158  ...  0.958344  0.982414  0.947885   \n",
       "4813  0.986985  0.991717  0.865844  ...  0.986945  0.988619  0.980466   \n",
       "4814  0.986556  0.975401  0.798458  ...  0.984730  0.986013  0.977325   \n",
       "4815  0.972904  0.966672  0.825539  ...  0.956058  0.984031  0.958849   \n",
       "\n",
       "            14        15        16        17        18        19        20  \n",
       "0     0.988377  0.960505  0.092287  0.114152  0.168468  0.409107  0.143744  \n",
       "1     0.988496  0.976164  0.056008  0.071097  0.116925  0.378149  0.112388  \n",
       "2     0.994419  0.980125  0.058663  0.051483  0.101680  0.373908  0.107997  \n",
       "3     0.991526  0.978826  0.084490  0.064109  0.116397  0.364355  0.101338  \n",
       "4     0.998567  0.995130  0.059962  0.052580  0.108792  0.358121  0.064819  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4811  0.998834  0.993999  0.069935  0.077047  0.111534  0.378788  0.069410  \n",
       "4812  0.976669  0.960906  0.073398  0.080276  0.164737  0.393641  0.182968  \n",
       "4813  0.994478  0.989071  0.048237  0.063770  0.101559  0.368176  0.081754  \n",
       "4814  0.987388  0.953415  0.052079  0.097728  0.134255  0.399315  0.131385  \n",
       "4815  0.977012  0.965487  0.078335  0.086431  0.136381  0.396775  0.157406  \n",
       "\n",
       "[4816 rows x 21 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "added_m_data = []\n",
    "\n",
    "for i in range(to_generate):\n",
    "    reconstruction = model.sample(sampled_mu, sampled_logvar)\n",
    "    reconstruction = added_m_data.append(reconstruction[0].detach().cpu().numpy())\n",
    "\n",
    "col_name = [x for x in range(0, 21)]\n",
    "x_added = pd.DataFrame(added_m_data, columns=col_name)\n",
    "x_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4812</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4816 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "...  ..\n",
       "4811  0\n",
       "4812  0\n",
       "4813  0\n",
       "4814  0\n",
       "4815  0\n",
       "\n",
       "[4816 rows x 1 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_targets = [[0] for x in range(to_generate)]\n",
    "y_added = pd.DataFrame(y_targets)\n",
    "\n",
    "y_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>0.510417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>0.108635</td>\n",
       "      <td>0.209030</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.173438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.108635</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.146875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>0.614583</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.186104</td>\n",
       "      <td>0.365741</td>\n",
       "      <td>0.180875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6768</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.097493</td>\n",
       "      <td>0.147157</td>\n",
       "      <td>0.287037</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>0.385417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.111978</td>\n",
       "      <td>0.182575</td>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.171984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>0.523773</td>\n",
       "      <td>0.846847</td>\n",
       "      <td>0.979460</td>\n",
       "      <td>0.989623</td>\n",
       "      <td>0.997662</td>\n",
       "      <td>0.949566</td>\n",
       "      <td>0.995882</td>\n",
       "      <td>0.990173</td>\n",
       "      <td>0.986897</td>\n",
       "      <td>0.891207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994618</td>\n",
       "      <td>0.996475</td>\n",
       "      <td>0.982644</td>\n",
       "      <td>0.998834</td>\n",
       "      <td>0.993999</td>\n",
       "      <td>0.069935</td>\n",
       "      <td>0.077047</td>\n",
       "      <td>0.111534</td>\n",
       "      <td>0.378788</td>\n",
       "      <td>0.069410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4812</th>\n",
       "      <td>0.557456</td>\n",
       "      <td>0.743915</td>\n",
       "      <td>0.937826</td>\n",
       "      <td>0.965978</td>\n",
       "      <td>0.988429</td>\n",
       "      <td>0.941798</td>\n",
       "      <td>0.983637</td>\n",
       "      <td>0.975114</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.817158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958344</td>\n",
       "      <td>0.982414</td>\n",
       "      <td>0.947885</td>\n",
       "      <td>0.976669</td>\n",
       "      <td>0.960906</td>\n",
       "      <td>0.073398</td>\n",
       "      <td>0.080276</td>\n",
       "      <td>0.164737</td>\n",
       "      <td>0.393641</td>\n",
       "      <td>0.182968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>0.577125</td>\n",
       "      <td>0.796695</td>\n",
       "      <td>0.986075</td>\n",
       "      <td>0.975226</td>\n",
       "      <td>0.997112</td>\n",
       "      <td>0.948879</td>\n",
       "      <td>0.996345</td>\n",
       "      <td>0.986985</td>\n",
       "      <td>0.991717</td>\n",
       "      <td>0.865844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986945</td>\n",
       "      <td>0.988619</td>\n",
       "      <td>0.980466</td>\n",
       "      <td>0.994478</td>\n",
       "      <td>0.989071</td>\n",
       "      <td>0.048237</td>\n",
       "      <td>0.063770</td>\n",
       "      <td>0.101559</td>\n",
       "      <td>0.368176</td>\n",
       "      <td>0.081754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>0.580795</td>\n",
       "      <td>0.759357</td>\n",
       "      <td>0.977377</td>\n",
       "      <td>0.944699</td>\n",
       "      <td>0.989590</td>\n",
       "      <td>0.952826</td>\n",
       "      <td>0.980197</td>\n",
       "      <td>0.986556</td>\n",
       "      <td>0.975401</td>\n",
       "      <td>0.798458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984730</td>\n",
       "      <td>0.986013</td>\n",
       "      <td>0.977325</td>\n",
       "      <td>0.987388</td>\n",
       "      <td>0.953415</td>\n",
       "      <td>0.052079</td>\n",
       "      <td>0.097728</td>\n",
       "      <td>0.134255</td>\n",
       "      <td>0.399315</td>\n",
       "      <td>0.131385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>0.565848</td>\n",
       "      <td>0.761814</td>\n",
       "      <td>0.947968</td>\n",
       "      <td>0.982503</td>\n",
       "      <td>0.987962</td>\n",
       "      <td>0.961639</td>\n",
       "      <td>0.988355</td>\n",
       "      <td>0.972904</td>\n",
       "      <td>0.966672</td>\n",
       "      <td>0.825539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956058</td>\n",
       "      <td>0.984031</td>\n",
       "      <td>0.958849</td>\n",
       "      <td>0.977012</td>\n",
       "      <td>0.965487</td>\n",
       "      <td>0.078335</td>\n",
       "      <td>0.086431</td>\n",
       "      <td>0.136381</td>\n",
       "      <td>0.396775</td>\n",
       "      <td>0.157406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10488 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "2707  0.510417  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "5398  0.750000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "4281  0.614583  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "6768  0.656250  1.000000  0.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "2836  0.385417  0.000000  0.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4811  0.523773  0.846847  0.979460  0.989623  0.997662  0.949566  0.995882   \n",
       "4812  0.557456  0.743915  0.937826  0.965978  0.988429  0.941798  0.983637   \n",
       "4813  0.577125  0.796695  0.986075  0.975226  0.997112  0.948879  0.996345   \n",
       "4814  0.580795  0.759357  0.977377  0.944699  0.989590  0.952826  0.980197   \n",
       "4815  0.565848  0.761814  0.947968  0.982503  0.987962  0.961639  0.988355   \n",
       "\n",
       "            7         8         9   ...        11        12        13  \\\n",
       "2707  1.000000  1.000000  1.000000  ...  1.000000  1.000000  1.000000   \n",
       "5398  1.000000  1.000000  1.000000  ...  1.000000  1.000000  1.000000   \n",
       "4281  1.000000  1.000000  1.000000  ...  1.000000  1.000000  1.000000   \n",
       "6768  1.000000  1.000000  0.000000  ...  1.000000  1.000000  1.000000   \n",
       "2836  1.000000  1.000000  0.000000  ...  1.000000  1.000000  1.000000   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4811  0.990173  0.986897  0.891207  ...  0.994618  0.996475  0.982644   \n",
       "4812  0.975114  0.965385  0.817158  ...  0.958344  0.982414  0.947885   \n",
       "4813  0.986985  0.991717  0.865844  ...  0.986945  0.988619  0.980466   \n",
       "4814  0.986556  0.975401  0.798458  ...  0.984730  0.986013  0.977325   \n",
       "4815  0.972904  0.966672  0.825539  ...  0.956058  0.984031  0.958849   \n",
       "\n",
       "            14        15        16        17        18        19        20  \n",
       "2707  1.000000  1.000000  0.004340  0.108635  0.209030  0.444444  0.173438  \n",
       "5398  1.000000  1.000000  0.028302  0.108635  0.130435  0.305556  0.146875  \n",
       "4281  1.000000  1.000000  0.004377  0.109192  0.186104  0.365741  0.180875  \n",
       "6768  1.000000  1.000000  0.001057  0.097493  0.147157  0.287037  0.175000  \n",
       "2836  1.000000  1.000000  0.003566  0.111978  0.182575  0.379630  0.171984  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4811  0.998834  0.993999  0.069935  0.077047  0.111534  0.378788  0.069410  \n",
       "4812  0.976669  0.960906  0.073398  0.080276  0.164737  0.393641  0.182968  \n",
       "4813  0.994478  0.989071  0.048237  0.063770  0.101559  0.368176  0.081754  \n",
       "4814  0.987388  0.953415  0.052079  0.097728  0.134255  0.399315  0.131385  \n",
       "4815  0.977012  0.965487  0.078335  0.086431  0.136381  0.396775  0.157406  \n",
       "\n",
       "[10488 rows x 21 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_fab = pd.concat([x_fab, x_added])\n",
    "x_fab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6768</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4812</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10488 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "2707  1\n",
       "5398  0\n",
       "4281  1\n",
       "6768  1\n",
       "2836  1\n",
       "...  ..\n",
       "4811  0\n",
       "4812  0\n",
       "4813  0\n",
       "4814  0\n",
       "4815  0\n",
       "\n",
       "[10488 rows x 1 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fab = pd.concat([y_raw, y_added])\n",
    "y_fab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw = torch.Tensor(x_raw.values)\n",
    "x_fab = torch.Tensor(x_fab.values)\n",
    "x_test = torch.Tensor(x_test.values)\n",
    "\n",
    "y_raw = torch.Tensor(y_raw.values)\n",
    "y_fab = torch.Tensor(y_fab.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        self.hidden_layer_1 = nn.Linear(self.in_dim, 10)\n",
    "        self.hidden_layer_2 = nn.Linear(10, 2)\n",
    "        self.output_layer = nn.Linear(2, self.out_dim)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layer_1(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.hidden_layer_2(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        y = self.output_layer(x)\n",
    "        y = self.activation(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10488, 1])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork(21, 1)\n",
    "\n",
    "# Test structure of model\n",
    "predictions = model.forward(x_fab)\n",
    "\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset to treat how the model picks an x, y combination from the dataset\n",
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    # Requires you to return data as a pair of _x, _y\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(loader, model, optimizer, loss_fn, batch_size):\n",
    "    loop = tqdm(loader)\n",
    "    \n",
    "    count = 0\n",
    "    ave_loss = 0.00\n",
    "    \n",
    "    # Loop per batch\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        predictions = model.forward(data)\n",
    "        \n",
    "        loss = loss_fn(predictions, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "        ave_loss += loss.item()\n",
    "        count += 1\n",
    "        \n",
    "    ave_loss = ave_loss / count\n",
    "    \n",
    "    return ave_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = MyCustomDataset(x=x_fab, y=y_fab)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    custom_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 431.00it/s, loss=0.0667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.14777974983956044\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 400.99it/s, loss=0.0578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.1945961326328741\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 427.33it/s, loss=0.0489]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.18429055214070275\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 462.40it/s, loss=0.0407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.1695900744189454\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 536.89it/s, loss=0.0333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.14988278766678517\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 553.67it/s, loss=0.0263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.1283351776293977\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 548.95it/s, loss=0.0201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.10783171712521204\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 546.10it/s, loss=0.0146] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.08799099808073184\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 549.21it/s, loss=0.01]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.06764238508301898\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 551.91it/s, loss=0.00692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.05303685761743125\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 604.16it/s, loss=0.00501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.04431428552828942\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 503.26it/s, loss=0.00381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.03876726153632715\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 518.07it/s, loss=0.00301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.03525439980028115\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 554.53it/s, loss=0.00247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.03304114119701081\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 549.38it/s, loss=0.00208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.031398043155400936\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 524.55it/s, loss=0.00178] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.030069915760882037\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 507.14it/s, loss=0.00154] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.028943165108119603\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 534.12it/s, loss=0.00136] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.027960108141650092\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 548.94it/s, loss=0.00122] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.02703694445848464\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 433.13it/s, loss=0.00109] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.026141970539331264\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 403.76it/s, loss=0.000995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.025327592271938787\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 408.85it/s, loss=0.000917]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.0246088759991901\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 419.64it/s, loss=0.000853]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.02396530707488729\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 434.79it/s, loss=0.000797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.02338042459334136\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 451.79it/s, loss=0.000749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.022847068364956365\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 455.24it/s, loss=0.000707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.022363883819459588\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 409.32it/s, loss=0.000669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.021926867685810546\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 424.31it/s, loss=0.000635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.021524673648569994\n",
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 409.32it/s, loss=0.000604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.021143416022983186\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 425.03it/s, loss=0.000576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.02077060692825969\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 409.70it/s, loss=0.000551]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.020393066958043365\n",
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 517.02it/s, loss=0.000527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.019994985921517258\n",
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 531.44it/s, loss=0.000504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.019569196415212736\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 559.47it/s, loss=0.000481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.019125561048911652\n",
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 477.16it/s, loss=0.000457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.01867626282244486\n",
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 537.71it/s, loss=0.000434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.018223408830074932\n",
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 531.48it/s, loss=0.000411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.017762959142808392\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 475.58it/s, loss=0.000388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.017293223723638458\n",
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 493.86it/s, loss=0.000365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.016818501664714793\n",
      "Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 535.14it/s, loss=0.000343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.01634609832382645\n",
      "Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 498.18it/s, loss=0.000321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.01588207309426064\n",
      "Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 519.75it/s, loss=0.0003]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.015432623635013779\n",
      "Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 543.10it/s, loss=0.000279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.015005430091352643\n",
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 534.66it/s, loss=0.00026] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.014606879329580498\n",
      "Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 530.87it/s, loss=0.000242]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.014237832201586196\n",
      "Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 445.67it/s, loss=0.000225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.013894321729763012\n",
      "Epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 488.71it/s, loss=0.000209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.013572671443663881\n",
      "Epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 464.34it/s, loss=0.000194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.013271054520145558\n",
      "Epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 485.85it/s, loss=0.00018] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.012988519895214257\n",
      "Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 510.02it/s, loss=0.000167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.012724543687841691\n",
      "Epoch: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 473.11it/s, loss=0.000155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.012478736540862043\n",
      "Epoch: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 468.29it/s, loss=0.000144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.01225058500942042\n",
      "Epoch: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 487.13it/s, loss=0.000134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.012039409210005254\n",
      "Epoch: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 462.78it/s, loss=0.000125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011844397636272232\n",
      "Epoch: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 524.38it/s, loss=0.000116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011664648402361798\n",
      "Epoch: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 501.56it/s, loss=0.000108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011499145432452696\n",
      "Epoch: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 525.27it/s, loss=0.000101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011346752850277734\n",
      "Epoch: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 524.60it/s, loss=9.48e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011206199644279933\n",
      "Epoch: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 520.74it/s, loss=8.89e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.01107620183996493\n",
      "Epoch: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 510.52it/s, loss=8.35e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010955577991151046\n",
      "Epoch: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 458.53it/s, loss=7.85e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.01084335144842399\n",
      "Epoch: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 501.98it/s, loss=7.4e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010738715716172628\n",
      "Epoch: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 519.16it/s, loss=6.98e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010640994568181857\n",
      "Epoch: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 529.82it/s, loss=6.6e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010549569436247097\n",
      "Epoch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 528.12it/s, loss=6.25e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010463900781702642\n",
      "Epoch: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 479.88it/s, loss=5.93e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010383506697539954\n",
      "Epoch: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 540.29it/s, loss=5.63e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010307945194291972\n",
      "Epoch: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 573.79it/s, loss=5.35e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.01023680658279216\n",
      "Epoch: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 564.38it/s, loss=5.09e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010169730770671466\n",
      "Epoch: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 436.36it/s, loss=4.86e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010106380172497903\n",
      "Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 489.01it/s, loss=4.64e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010046455905432529\n",
      "Epoch: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 520.56it/s, loss=4.43e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009989679991949394\n",
      "Epoch: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 491.81it/s, loss=4.24e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009935804131577209\n",
      "Epoch: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 1334/2098 [00:02<00:01, 398.34it/s, loss=6.77e-5] "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    \n",
    "    ave_loss = train_nn(\n",
    "        train_loader,\n",
    "        model,\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "        batch_size\n",
    "    )\n",
    "    \n",
    "    losses.append(ave_loss)\n",
    "    \n",
    "    print(\"Ave Loss: {}\".format(ave_loss))\n",
    "    \n",
    "    state = { 'state_dict': model.state_dict() }\n",
    "\n",
    "    # acc: 0.90832, f1: 0.78\n",
    "    # torch.save(state, \"annthyroid_model.pth\")\n",
    "    \n",
    "    torch.save(state, \"annthyroid_model2.pth\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses, label='loss', color='red')\n",
    "plt.title('Training Evaluation', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Error Value', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.forward(x_test)\n",
    "predictions = predictions.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == 0:\n",
    "        y_test[i] = -1\n",
    "        \n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1418, 2)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reverse_ohe(preds):\n",
    "    ohe = []\n",
    "    \n",
    "    for i in preds:\n",
    "        if i > 0.5:\n",
    "            ohe.append([1])\n",
    "        else:\n",
    "            ohe.append([-1])\n",
    "        \n",
    "    return ohe\n",
    "\n",
    "preds = reverse_ohe(predictions)\n",
    "preds = np.array(preds)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8533145275035261\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}'.format(accuracy_score(preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.32      0.49       307\n",
      "           1       0.84      1.00      0.91      1111\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      1418\n",
      "   macro avg       0.92      0.66      0.70      1418\n",
      "weighted avg       0.88      0.85      0.82      1418\n",
      " samples avg       0.85      0.85      0.85      1418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(preds, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae03ce6f38b86b61e05d3f0e4339342b058157d9f0092e90d0a518f5ecf9e2f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
