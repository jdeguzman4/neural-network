{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.197324</td>\n",
       "      <td>0.300926</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.239583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.164345</td>\n",
       "      <td>0.235786</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.165625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.479167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.167224</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.091922</td>\n",
       "      <td>0.125418</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.129688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.142061</td>\n",
       "      <td>0.229097</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.235938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7085</th>\n",
       "      <td>0.604167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.113092</td>\n",
       "      <td>0.128763</td>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.030641</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7087</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.147157</td>\n",
       "      <td>0.231481</td>\n",
       "      <td>0.206250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7088</th>\n",
       "      <td>0.354167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.147157</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.154688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7089</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.132107</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7090 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0   1   2   3   4   5   6   7   8   9   ...  12  13  14  15  \\\n",
       "0     0.750000   1   0   1   1   1   1   1   0   1  ...   1   1   1   1   \n",
       "1     0.239583   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "2     0.479167   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "3     0.656250   0   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "4     0.229167   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "...        ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..   \n",
       "7085  0.604167   1   1   1   1   1   1   1   1   1  ...   1   1   1   0   \n",
       "7086  0.520833   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "7087  0.520833   1   1   1   1   1   1   1   1   1  ...   1   1   1   0   \n",
       "7088  0.354167   0   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "7089  0.750000   1   1   1   1   1   1   1   1   1  ...   1   1   1   0   \n",
       "\n",
       "            16        17        18        19        20  21  \n",
       "0     0.001132  0.080780  0.197324  0.300926  0.225000   1  \n",
       "1     0.000472  0.164345  0.235786  0.537037  0.165625   1  \n",
       "2     0.003585  0.130919  0.167224  0.527778  0.118750   1  \n",
       "3     0.001698  0.091922  0.125418  0.337963  0.129688   1  \n",
       "4     0.000472  0.142061  0.229097  0.337963  0.235938   1  \n",
       "...        ...       ...       ...       ...       ...  ..  \n",
       "7085  0.004717  0.113092  0.128763  0.379630  0.121875   1  \n",
       "7086  0.200000  0.030641  0.005017  0.333333  0.005469  -1  \n",
       "7087  0.001434  0.109192  0.147157  0.231481  0.206250   1  \n",
       "7088  0.005283  0.109192  0.147157  0.333333  0.154688   1  \n",
       "7089  0.001057  0.109192  0.132107  0.337963  0.137500   1  \n",
       "\n",
       "[7090 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_raw = pd.read_csv(\"wdbc.csv\", header=None)\n",
    "df_raw = pd.read_csv(\"./annthyroid.csv\", header=None)\n",
    "\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rongavilla\\AppData\\Local\\Temp\\ipykernel_19400\\46608714.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw[21].loc[df_raw[21] == -1] = 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.197324</td>\n",
       "      <td>0.300926</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.239583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.164345</td>\n",
       "      <td>0.235786</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.165625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.479167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.167224</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.091922</td>\n",
       "      <td>0.125418</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.129688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.142061</td>\n",
       "      <td>0.229097</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.235938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7085</th>\n",
       "      <td>0.604167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.113092</td>\n",
       "      <td>0.128763</td>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.030641</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7087</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.147157</td>\n",
       "      <td>0.231481</td>\n",
       "      <td>0.206250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7088</th>\n",
       "      <td>0.354167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.147157</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.154688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7089</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.132107</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7090 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0   1   2   3   4   5   6   7   8   9   ...  12  13  14  15  \\\n",
       "0     0.750000   1   0   1   1   1   1   1   0   1  ...   1   1   1   1   \n",
       "1     0.239583   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "2     0.479167   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "3     0.656250   0   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "4     0.229167   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "...        ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..   \n",
       "7085  0.604167   1   1   1   1   1   1   1   1   1  ...   1   1   1   0   \n",
       "7086  0.520833   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "7087  0.520833   1   1   1   1   1   1   1   1   1  ...   1   1   1   0   \n",
       "7088  0.354167   0   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "7089  0.750000   1   1   1   1   1   1   1   1   1  ...   1   1   1   0   \n",
       "\n",
       "            16        17        18        19        20  21  \n",
       "0     0.001132  0.080780  0.197324  0.300926  0.225000   1  \n",
       "1     0.000472  0.164345  0.235786  0.537037  0.165625   1  \n",
       "2     0.003585  0.130919  0.167224  0.527778  0.118750   1  \n",
       "3     0.001698  0.091922  0.125418  0.337963  0.129688   1  \n",
       "4     0.000472  0.142061  0.229097  0.337963  0.235938   1  \n",
       "...        ...       ...       ...       ...       ...  ..  \n",
       "7085  0.004717  0.113092  0.128763  0.379630  0.121875   1  \n",
       "7086  0.200000  0.030641  0.005017  0.333333  0.005469   0  \n",
       "7087  0.001434  0.109192  0.147157  0.231481  0.206250   1  \n",
       "7088  0.005283  0.109192  0.147157  0.333333  0.154688   1  \n",
       "7089  0.001057  0.109192  0.132107  0.337963  0.137500   1  \n",
       "\n",
       "[7090 rows x 22 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw[21].loc[df_raw[21] == -1] = 0\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7085</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7087</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7088</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7089</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7090 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1\n",
       "0     0  1\n",
       "1     0  1\n",
       "2     0  1\n",
       "3     0  1\n",
       "4     0  1\n",
       "...  .. ..\n",
       "7085  0  1\n",
       "7086  1  0\n",
       "7087  0  1\n",
       "7088  0  1\n",
       "7089  0  1\n",
       "\n",
       "[7090 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(df_raw[21])\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.197324</td>\n",
       "      <td>0.300926</td>\n",
       "      <td>0.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.239583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.164345</td>\n",
       "      <td>0.235786</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.165625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.479167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.167224</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.118750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.091922</td>\n",
       "      <td>0.125418</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.129688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.142061</td>\n",
       "      <td>0.229097</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.235938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9   ...   11   12   13  \\\n",
       "0  0.750000  1.0  0.0  1.0  1.0  1.0  1.0  1.0  0.0  1.0  ...  1.0  1.0  1.0   \n",
       "1  0.239583  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "2  0.479167  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "3  0.656250  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "4  0.229167  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "\n",
       "    14   15        16        17        18        19        20  \n",
       "0  1.0  1.0  0.001132  0.080780  0.197324  0.300926  0.225000  \n",
       "1  1.0  1.0  0.000472  0.164345  0.235786  0.537037  0.165625  \n",
       "2  1.0  1.0  0.003585  0.130919  0.167224  0.527778  0.118750  \n",
       "3  1.0  1.0  0.001698  0.091922  0.125418  0.337963  0.129688  \n",
       "4  1.0  1.0  0.000472  0.142061  0.229097  0.337963  0.235938  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_raw.iloc[:,:-1]\n",
    "x = (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "x.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw, x_test, y_raw, y_test = train_test_split(x, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of 0 in the training set is: 428\n",
      "The number of 1 in the training set is: 5244\n",
      "Goal: Generate 4816 datasets for 0.\n"
     ]
    }
   ],
   "source": [
    "zero_count = y_raw[0][y_raw[0] == 1].count()\n",
    "one_count = y_raw[1][y_raw[1] == 1].count()\n",
    "\n",
    "print('The number of 0 in the training set is: {}'.format(zero_count))\n",
    "print('The number of 1 in the training set is: {}'.format(one_count))\n",
    "\n",
    "to_generate = one_count-zero_count\n",
    "print('Goal: Generate {} datasets for 0.'.format(to_generate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.108635</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.146875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020925</td>\n",
       "      <td>0.069638</td>\n",
       "      <td>0.143813</td>\n",
       "      <td>0.402778</td>\n",
       "      <td>0.126563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>0.489583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.137736</td>\n",
       "      <td>0.125348</td>\n",
       "      <td>0.142140</td>\n",
       "      <td>0.439815</td>\n",
       "      <td>0.118750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>0.281250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.194340</td>\n",
       "      <td>0.113092</td>\n",
       "      <td>0.105351</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.084375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>0.843750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011698</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.162207</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.168750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1    2    3    4    5    6    7    8    9   ...   11   12  \\\n",
       "5398  0.750000  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "2900  0.708333  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "5002  0.489583  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "2827  0.281250  1.0  1.0  1.0  1.0  1.0  1.0  0.0  1.0  1.0  ...  1.0  1.0   \n",
       "4652  0.843750  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "\n",
       "       13   14   15        16        17        18        19        20  \n",
       "5398  1.0  1.0  1.0  0.028302  0.108635  0.130435  0.305556  0.146875  \n",
       "2900  1.0  1.0  1.0  0.020925  0.069638  0.143813  0.402778  0.126563  \n",
       "5002  1.0  1.0  1.0  0.137736  0.125348  0.142140  0.439815  0.118750  \n",
       "2827  1.0  1.0  1.0  0.194340  0.113092  0.105351  0.458333  0.084375  \n",
       "4652  1.0  1.0  1.0  0.011698  0.080780  0.162207  0.337963  0.168750  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_missing = x_raw[y_raw[0] == 1]\n",
    "x_missing.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, num_features=8, num_dim=21):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        \n",
    "        self.num_features = num_features\n",
    "        self.num_dim = num_dim\n",
    "        \n",
    "        self.encoder_layer_1 = nn.Linear(in_features=self.num_dim, out_features=14)\n",
    "        self.encoder_layer_2 = nn.Linear(in_features=14, out_features=(self.num_features * 2))\n",
    "        \n",
    "        self.decoder_layer_1 = nn.Linear(in_features=self.num_features, out_features=14)\n",
    "        self.decoder_layer_2 = nn.Linear(in_features=14, out_features=self.num_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU() # hidden layers\n",
    "        self.sigmoid = nn.Sigmoid() # output layer\n",
    "        \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        :param mu: mean from the encoder's latent space\n",
    "        :param log_var: log variance from the encoder's latent space\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5*log_var) # standard deviation\n",
    "        eps = torch.randn_like(std)  # `randn_like` as we need the same size\n",
    "        sample = mu + (eps * std)    # sampling as if coming from the input space\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def encode(self, x):\n",
    "        # encoding\n",
    "        #x = F.relu(self.encoder_layer_1(x))\n",
    "        x = self.encoder_layer_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.encoder_layer_2(x).view(-1, 2, self.num_features)\n",
    "        \n",
    "        # get `mu` and `log_var`\n",
    "        mu = x[:, 0, :] # the first feature values as mean\n",
    "        log_var = x[:, 1, :] # the other feature values as variance\n",
    "        \n",
    "        # get the latent vector through reparameterization\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        \n",
    "        return z, mu, log_var\n",
    "    \n",
    "    def decode(self, z, mu, log_var):\n",
    "        # decoding\n",
    "        #x = F.relu(self.decoder_layer_1(z))\n",
    "        x = self.decoder_layer_1(z)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        #reconstruction = torch.sigmoid(self.decoder_layer_2(x))\n",
    "        reconstruction = self.decoder_layer_2(x)\n",
    "        reconstruction = self.sigmoid(reconstruction)\n",
    "        \n",
    "        return reconstruction, mu, log_var\n",
    "    \n",
    "    # Utility function to generate new data based on:\n",
    "    # mu: The average that you want to have (should be the same size as num_features)\n",
    "    # log_var: The variance that you want to have (should be the same size as num_features)\n",
    "    def sample(self, mu, log_var):\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        reconstruction, mu, log_var = self.decode(z, mu, log_var)\n",
    "        \n",
    "        return reconstruction\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        z, mu, log_var = self.encode(x)\n",
    "        reconstruction, mu, log_var = self.decode(z, mu, log_var)\n",
    "        \n",
    "        return reconstruction, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset to treat how the model picks an x, y combination from the dataset\n",
    "class AutoencoderDataset(Dataset):\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    # Requires you to return data as a pair of _x, _y\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.x[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final loss is a combination of the reconstruction loss (first argument) and the loss from an assumed distribution (i.e. Normal / Gaussian distribution)\n",
    "def final_loss(bce_loss, mu, logvar):\n",
    "    \"\"\"\n",
    "    This function will add the reconstruction loss (BCELoss) and the \n",
    "    KL-Divergence.\n",
    "    KL-Divergence = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    :param bce_loss: recontruction loss\n",
    "    :param mu: the mean from the latent vector\n",
    "    :param logvar: log variance from the latent vector\n",
    "    \"\"\"\n",
    "    BCE = bce_loss \n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 8\n",
    "model = VariationalAutoencoder(num_features=num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn, batch_size):\n",
    "    loop = tqdm(loader)\n",
    "    \n",
    "    count = 0\n",
    "    ave_loss = 0.00\n",
    "    \n",
    "    # Loop per batch\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        reconstruction, mu, logvar = model.forward(data)\n",
    "        \n",
    "        loss = loss_fn(reconstruction, targets)\n",
    "        \n",
    "        loss = final_loss(loss, mu, logvar)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "        ave_loss += loss.item()\n",
    "        count += 1\n",
    "        \n",
    "    ave_loss = ave_loss / count\n",
    "    \n",
    "    return ave_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_missing = torch.Tensor(np.array(x_missing))\n",
    "\n",
    "# use Dataloader for Autoencoder \n",
    "custom_dataset = AutoencoderDataset(x_missing)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    custom_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 300.30it/s, loss=1.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 1.6659989592640898\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 438.49it/s, loss=1]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 1.3649247621381007\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 440.25it/s, loss=0.902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 1.1118607278480086\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 451.17it/s, loss=0.815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.9400712813055793\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 456.44it/s, loss=0.724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.8273812553217245\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 449.10it/s, loss=0.681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.7493171684963759\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 406.71it/s, loss=0.641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.69328661020412\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 478.26it/s, loss=0.632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.6539307229740675\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 474.38it/s, loss=0.617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.6289566062217535\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 468.62it/s, loss=0.582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.6109436805858168\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 453.17it/s, loss=0.584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.5948625463385915\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 440.75it/s, loss=0.602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.5810918045598407\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 449.13it/s, loss=0.612]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.5674758941628212\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 466.28it/s, loss=0.529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.5534093920574632\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 471.39it/s, loss=0.563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.5365710480268612\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 447.03it/s, loss=0.542]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.520743824714838\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 449.32it/s, loss=0.49] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.5102164662161539\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 437.78it/s, loss=0.484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.49705063187798787\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 483.36it/s, loss=0.51] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.48564002680224044\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 437.26it/s, loss=0.474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.4666432745234911\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 464.95it/s, loss=0.464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.4579733724510947\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 461.15it/s, loss=0.44] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.4457390353430149\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 388.21it/s, loss=0.459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.4380365544280341\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 471.24it/s, loss=0.427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.42178170105745627\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 475.79it/s, loss=0.435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.41234492319960925\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 445.20it/s, loss=0.402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.4010173099678616\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 467.05it/s, loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.3934387675551481\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 450.08it/s, loss=0.41] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.3799564585436222\n",
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 455.29it/s, loss=0.392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.37853617342405543\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 484.29it/s, loss=0.38] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.36702798410903575\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 439.16it/s, loss=0.398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.35575096378492754\n",
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 422.14it/s, loss=0.335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.3455791948146598\n",
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 405.40it/s, loss=0.379]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.3406266843856767\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 425.81it/s, loss=0.332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.3328702087665713\n",
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 479.09it/s, loss=0.365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.32955912032792734\n",
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 450.64it/s, loss=0.367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.32350670528966324\n",
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 485.40it/s, loss=0.35] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.3144003385028174\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 454.97it/s, loss=0.329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.30642069858867066\n",
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 426.99it/s, loss=0.338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2991024153523667\n",
      "Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 440.60it/s, loss=0.354]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2945626953313517\n",
      "Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 481.72it/s, loss=0.331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.29332091087518736\n",
      "Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 458.71it/s, loss=0.304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.28601808655400607\n",
      "Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 477.09it/s, loss=0.324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2843999160930168\n",
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 449.82it/s, loss=0.311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2802716843610586\n",
      "Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 438.91it/s, loss=0.308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.27719396006229313\n",
      "Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 468.29it/s, loss=0.296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2723393396929253\n",
      "Epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 461.68it/s, loss=0.299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2698511720396752\n",
      "Epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 467.58it/s, loss=0.307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2634352747091027\n",
      "Epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 442.00it/s, loss=0.294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.264123548082141\n",
      "Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 445.48it/s, loss=0.325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2617186846774678\n",
      "Epoch: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 438.67it/s, loss=0.298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2584400932456172\n",
      "Epoch: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 483.87it/s, loss=0.303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2571634813103565\n",
      "Epoch: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 442.85it/s, loss=0.294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2537989872832631\n",
      "Epoch: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 476.53it/s, loss=0.295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.25254574435394866\n",
      "Epoch: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 428.26it/s, loss=0.276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.25017627917749935\n",
      "Epoch: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 396.50it/s, loss=0.29] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.24837629011897153\n",
      "Epoch: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 471.77it/s, loss=0.291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.24769919920106268\n",
      "Epoch: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 468.77it/s, loss=0.303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2478017507250919\n",
      "Epoch: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 478.48it/s, loss=0.27] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2443763059239055\n",
      "Epoch: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 456.47it/s, loss=0.278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.24428552389144897\n",
      "Epoch: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 423.44it/s, loss=0.274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.24126841127872467\n",
      "Epoch: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 468.14it/s, loss=0.265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.24043270876241285\n",
      "Epoch: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 457.68it/s, loss=0.273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2374341311149819\n",
      "Epoch: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 468.84it/s, loss=0.259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23829712614763615\n",
      "Epoch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 471.60it/s, loss=0.278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23658329491005387\n",
      "Epoch: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 441.17it/s, loss=0.309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2376591909763425\n",
      "Epoch: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 442.74it/s, loss=0.268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23575669960227125\n",
      "Epoch: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 470.21it/s, loss=0.281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23566793754350307\n",
      "Epoch: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 458.72it/s, loss=0.249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23335478558789852\n",
      "Epoch: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 442.28it/s, loss=0.263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23462164783200554\n",
      "Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 464.28it/s, loss=0.273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23381146216808363\n",
      "Epoch: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 447.93it/s, loss=0.265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23406690948231276\n",
      "Epoch: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 440.38it/s, loss=0.289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23426322864238605\n",
      "Epoch: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 464.19it/s, loss=0.277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23185268876164458\n",
      "Epoch: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 457.03it/s, loss=0.262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23064721860857898\n",
      "Epoch: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 468.36it/s, loss=0.273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23089453127495077\n",
      "Epoch: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 473.92it/s, loss=0.308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.23057133046000503\n",
      "Epoch: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 418.27it/s, loss=0.256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22964458496764648\n",
      "Epoch: 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 425.33it/s, loss=0.261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2284532366103904\n",
      "Epoch: 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 351.71it/s, loss=0.282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22935043829818105\n",
      "Epoch: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 398.04it/s, loss=0.263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2279784606639729\n",
      "Epoch: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 433.42it/s, loss=0.262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22809677276500437\n",
      "Epoch: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 351.97it/s, loss=0.249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22808935891750248\n",
      "Epoch: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 396.29it/s, loss=0.252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2273944914340973\n",
      "Epoch: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 349.10it/s, loss=0.262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22763228866943094\n",
      "Epoch: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 347.96it/s, loss=0.261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22679632139760394\n",
      "Epoch: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 363.15it/s, loss=0.265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22790107581504557\n",
      "Epoch: 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 378.77it/s, loss=0.251]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22615024915268256\n",
      "Epoch: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 411.56it/s, loss=0.276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2262886232414911\n",
      "Epoch: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 394.99it/s, loss=0.272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2270331417405328\n",
      "Epoch: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 405.83it/s, loss=0.264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22564063810331877\n",
      "Epoch: 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 384.12it/s, loss=0.266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22504976617042408\n",
      "Epoch: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 410.80it/s, loss=0.293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22648296418578126\n",
      "Epoch: 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 404.78it/s, loss=0.274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22743721739497297\n",
      "Epoch: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 423.07it/s, loss=0.254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2241708962030189\n",
      "Epoch: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 406.10it/s, loss=0.279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22608317278845366\n",
      "Epoch: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 369.19it/s, loss=0.244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22444700588320576\n",
      "Epoch: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 416.21it/s, loss=0.259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22439042288203573\n",
      "Epoch: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 400.11it/s, loss=0.281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.2242289100622022\n",
      "Epoch: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 416.69it/s, loss=0.256]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.22492332617903865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    \n",
    "    ave_loss = train_fn(\n",
    "        train_loader,\n",
    "        model,\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "        batch_size\n",
    "    )\n",
    "    \n",
    "    losses.append(ave_loss)\n",
    "    \n",
    "    print(\"Ave Loss: {}\".format(ave_loss))\n",
    "    \n",
    "    state = { 'state_dict': model.state_dict() }\n",
    "\n",
    "    torch.save(state, \"variational-autoencoder.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses, label='loss', color='red')\n",
    "plt.title('Training Evaluation', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Error Value', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rongavilla\\AppData\\Local\\Temp\\ipykernel_19400\\2826375446.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  sampled_mu = torch.Tensor([np.zeros(num_features)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vector of zero tensors representing 0 average per num_feature (right in the middle of the dist)\n",
    "sampled_mu = torch.Tensor([np.zeros(num_features)])\n",
    "\n",
    "# Create a vector of zero tensors representing 0 standard deviations away from the mean to create variations\n",
    "# Change this is you want to sample away from the mean to create \"off-quality\" data\n",
    "sampled_logvar = torch.Tensor([np.zeros(num_features)])\n",
    "\n",
    "sampled_logvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5408, 0.7832, 0.9508, 0.9858, 0.9922, 0.9288, 0.9938, 0.9862, 0.9753,\n",
       "         0.8362, 0.9344, 0.9819, 0.9943, 0.9468, 0.9912, 0.9631, 0.0823, 0.1037,\n",
       "         0.1743, 0.3944, 0.1444]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction = model.sample(sampled_mu, sampled_logvar)\n",
    "reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>0.510417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>0.108635</td>\n",
       "      <td>0.209030</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.173438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.108635</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.146875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>0.614583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.186104</td>\n",
       "      <td>0.365741</td>\n",
       "      <td>0.180875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6768</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.097493</td>\n",
       "      <td>0.147157</td>\n",
       "      <td>0.287037</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>0.385417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.111978</td>\n",
       "      <td>0.182575</td>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.171984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>0.572917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.111978</td>\n",
       "      <td>0.220736</td>\n",
       "      <td>0.398148</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>0.739583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.177258</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>0.385417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.175487</td>\n",
       "      <td>0.224080</td>\n",
       "      <td>0.342593</td>\n",
       "      <td>0.229688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.013928</td>\n",
       "      <td>0.050167</td>\n",
       "      <td>0.162037</td>\n",
       "      <td>0.090625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>0.614583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.142061</td>\n",
       "      <td>0.185619</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.193750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5672 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1    2    3    4    5    6    7    8    9   ...   11   12  \\\n",
       "2707  0.510417  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "5398  0.750000  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "4281  0.614583  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "6768  0.656250  1.0  0.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  ...  1.0  1.0   \n",
       "2836  0.385417  0.0  0.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  ...  1.0  1.0   \n",
       "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "905   0.572917  1.0  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "5192  0.739583  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "3980  0.385417  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "235   0.500000  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "5157  0.614583  1.0  1.0  1.0  1.0  1.0  1.0  0.0  1.0  1.0  ...  1.0  1.0   \n",
       "\n",
       "       13   14   15        16        17        18        19        20  \n",
       "2707  1.0  1.0  1.0  0.004340  0.108635  0.209030  0.444444  0.173438  \n",
       "5398  1.0  1.0  1.0  0.028302  0.108635  0.130435  0.305556  0.146875  \n",
       "4281  1.0  1.0  1.0  0.004377  0.109192  0.186104  0.365741  0.180875  \n",
       "6768  1.0  1.0  1.0  0.001057  0.097493  0.147157  0.287037  0.175000  \n",
       "2836  1.0  1.0  1.0  0.003566  0.111978  0.182575  0.379630  0.171984  \n",
       "...   ...  ...  ...       ...       ...       ...       ...       ...  \n",
       "905   1.0  1.0  1.0  0.000377  0.111978  0.220736  0.398148  0.200000  \n",
       "5192  1.0  1.0  0.0  0.002642  0.109192  0.177258  0.361111  0.175000  \n",
       "3980  1.0  1.0  1.0  0.002830  0.175487  0.224080  0.342593  0.229688  \n",
       "235   1.0  1.0  1.0  0.000189  0.013928  0.050167  0.162037  0.090625  \n",
       "5157  1.0  1.0  1.0  0.003208  0.142061  0.185619  0.337963  0.193750  \n",
       "\n",
       "[5672 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_fab = x_raw\n",
    "x_fab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.606780</td>\n",
       "      <td>0.818484</td>\n",
       "      <td>0.996789</td>\n",
       "      <td>0.998934</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>0.995891</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>0.997701</td>\n",
       "      <td>0.995391</td>\n",
       "      <td>0.962915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999353</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>0.997725</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.998156</td>\n",
       "      <td>0.020480</td>\n",
       "      <td>0.021457</td>\n",
       "      <td>0.059792</td>\n",
       "      <td>0.341579</td>\n",
       "      <td>0.055466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.580273</td>\n",
       "      <td>0.849612</td>\n",
       "      <td>0.972217</td>\n",
       "      <td>0.992619</td>\n",
       "      <td>0.993301</td>\n",
       "      <td>0.975243</td>\n",
       "      <td>0.994895</td>\n",
       "      <td>0.987472</td>\n",
       "      <td>0.990527</td>\n",
       "      <td>0.879395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991503</td>\n",
       "      <td>0.995998</td>\n",
       "      <td>0.966399</td>\n",
       "      <td>0.996183</td>\n",
       "      <td>0.987227</td>\n",
       "      <td>0.051334</td>\n",
       "      <td>0.046672</td>\n",
       "      <td>0.093138</td>\n",
       "      <td>0.368847</td>\n",
       "      <td>0.100020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.562247</td>\n",
       "      <td>0.750371</td>\n",
       "      <td>0.918686</td>\n",
       "      <td>0.976081</td>\n",
       "      <td>0.980736</td>\n",
       "      <td>0.938199</td>\n",
       "      <td>0.987357</td>\n",
       "      <td>0.980401</td>\n",
       "      <td>0.961560</td>\n",
       "      <td>0.851059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976762</td>\n",
       "      <td>0.984647</td>\n",
       "      <td>0.932489</td>\n",
       "      <td>0.977247</td>\n",
       "      <td>0.944809</td>\n",
       "      <td>0.088092</td>\n",
       "      <td>0.128199</td>\n",
       "      <td>0.186410</td>\n",
       "      <td>0.402511</td>\n",
       "      <td>0.162600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.575588</td>\n",
       "      <td>0.731225</td>\n",
       "      <td>0.958497</td>\n",
       "      <td>0.987594</td>\n",
       "      <td>0.990177</td>\n",
       "      <td>0.968600</td>\n",
       "      <td>0.994860</td>\n",
       "      <td>0.975201</td>\n",
       "      <td>0.979150</td>\n",
       "      <td>0.792534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985433</td>\n",
       "      <td>0.993880</td>\n",
       "      <td>0.969577</td>\n",
       "      <td>0.994137</td>\n",
       "      <td>0.981959</td>\n",
       "      <td>0.058319</td>\n",
       "      <td>0.098128</td>\n",
       "      <td>0.160436</td>\n",
       "      <td>0.401752</td>\n",
       "      <td>0.136039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.575753</td>\n",
       "      <td>0.786442</td>\n",
       "      <td>0.929183</td>\n",
       "      <td>0.970597</td>\n",
       "      <td>0.981102</td>\n",
       "      <td>0.942701</td>\n",
       "      <td>0.984959</td>\n",
       "      <td>0.975835</td>\n",
       "      <td>0.976468</td>\n",
       "      <td>0.849664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976589</td>\n",
       "      <td>0.984034</td>\n",
       "      <td>0.941607</td>\n",
       "      <td>0.977117</td>\n",
       "      <td>0.951324</td>\n",
       "      <td>0.092414</td>\n",
       "      <td>0.099082</td>\n",
       "      <td>0.151433</td>\n",
       "      <td>0.388351</td>\n",
       "      <td>0.129462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>0.580733</td>\n",
       "      <td>0.830452</td>\n",
       "      <td>0.966683</td>\n",
       "      <td>0.981308</td>\n",
       "      <td>0.986558</td>\n",
       "      <td>0.966809</td>\n",
       "      <td>0.992561</td>\n",
       "      <td>0.966433</td>\n",
       "      <td>0.976364</td>\n",
       "      <td>0.843398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988135</td>\n",
       "      <td>0.995695</td>\n",
       "      <td>0.951360</td>\n",
       "      <td>0.995888</td>\n",
       "      <td>0.980846</td>\n",
       "      <td>0.091893</td>\n",
       "      <td>0.072316</td>\n",
       "      <td>0.114093</td>\n",
       "      <td>0.389372</td>\n",
       "      <td>0.139226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4812</th>\n",
       "      <td>0.549437</td>\n",
       "      <td>0.751886</td>\n",
       "      <td>0.956587</td>\n",
       "      <td>0.981358</td>\n",
       "      <td>0.984300</td>\n",
       "      <td>0.970934</td>\n",
       "      <td>0.994405</td>\n",
       "      <td>0.974678</td>\n",
       "      <td>0.967106</td>\n",
       "      <td>0.831706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993121</td>\n",
       "      <td>0.996327</td>\n",
       "      <td>0.964202</td>\n",
       "      <td>0.996118</td>\n",
       "      <td>0.981758</td>\n",
       "      <td>0.066331</td>\n",
       "      <td>0.100421</td>\n",
       "      <td>0.122299</td>\n",
       "      <td>0.380968</td>\n",
       "      <td>0.126737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>0.562664</td>\n",
       "      <td>0.824325</td>\n",
       "      <td>0.991001</td>\n",
       "      <td>0.994051</td>\n",
       "      <td>0.996786</td>\n",
       "      <td>0.982950</td>\n",
       "      <td>0.995018</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996481</td>\n",
       "      <td>0.882165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995603</td>\n",
       "      <td>0.997470</td>\n",
       "      <td>0.988606</td>\n",
       "      <td>0.993824</td>\n",
       "      <td>0.990461</td>\n",
       "      <td>0.036137</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.078104</td>\n",
       "      <td>0.355447</td>\n",
       "      <td>0.053794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>0.582847</td>\n",
       "      <td>0.789644</td>\n",
       "      <td>0.976714</td>\n",
       "      <td>0.995137</td>\n",
       "      <td>0.995449</td>\n",
       "      <td>0.980553</td>\n",
       "      <td>0.997388</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.988778</td>\n",
       "      <td>0.914114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995266</td>\n",
       "      <td>0.996554</td>\n",
       "      <td>0.982683</td>\n",
       "      <td>0.993867</td>\n",
       "      <td>0.983567</td>\n",
       "      <td>0.036973</td>\n",
       "      <td>0.063684</td>\n",
       "      <td>0.111289</td>\n",
       "      <td>0.389402</td>\n",
       "      <td>0.095167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>0.579723</td>\n",
       "      <td>0.794641</td>\n",
       "      <td>0.931766</td>\n",
       "      <td>0.981411</td>\n",
       "      <td>0.983284</td>\n",
       "      <td>0.955255</td>\n",
       "      <td>0.990775</td>\n",
       "      <td>0.983206</td>\n",
       "      <td>0.970264</td>\n",
       "      <td>0.885080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984712</td>\n",
       "      <td>0.991678</td>\n",
       "      <td>0.941683</td>\n",
       "      <td>0.987410</td>\n",
       "      <td>0.964154</td>\n",
       "      <td>0.064336</td>\n",
       "      <td>0.085371</td>\n",
       "      <td>0.138990</td>\n",
       "      <td>0.377566</td>\n",
       "      <td>0.134740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4816 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.606780  0.818484  0.996789  0.998934  0.999475  0.995891  0.999933   \n",
       "1     0.580273  0.849612  0.972217  0.992619  0.993301  0.975243  0.994895   \n",
       "2     0.562247  0.750371  0.918686  0.976081  0.980736  0.938199  0.987357   \n",
       "3     0.575588  0.731225  0.958497  0.987594  0.990177  0.968600  0.994860   \n",
       "4     0.575753  0.786442  0.929183  0.970597  0.981102  0.942701  0.984959   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4811  0.580733  0.830452  0.966683  0.981308  0.986558  0.966809  0.992561   \n",
       "4812  0.549437  0.751886  0.956587  0.981358  0.984300  0.970934  0.994405   \n",
       "4813  0.562664  0.824325  0.991001  0.994051  0.996786  0.982950  0.995018   \n",
       "4814  0.582847  0.789644  0.976714  0.995137  0.995449  0.980553  0.997388   \n",
       "4815  0.579723  0.794641  0.931766  0.981411  0.983284  0.955255  0.990775   \n",
       "\n",
       "            7         8         9   ...        11        12        13  \\\n",
       "0     0.997701  0.995391  0.962915  ...  0.999353  0.999918  0.997725   \n",
       "1     0.987472  0.990527  0.879395  ...  0.991503  0.995998  0.966399   \n",
       "2     0.980401  0.961560  0.851059  ...  0.976762  0.984647  0.932489   \n",
       "3     0.975201  0.979150  0.792534  ...  0.985433  0.993880  0.969577   \n",
       "4     0.975835  0.976468  0.849664  ...  0.976589  0.984034  0.941607   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4811  0.966433  0.976364  0.843398  ...  0.988135  0.995695  0.951360   \n",
       "4812  0.974678  0.967106  0.831706  ...  0.993121  0.996327  0.964202   \n",
       "4813  0.996607  0.996481  0.882165  ...  0.995603  0.997470  0.988606   \n",
       "4814  0.996000  0.988778  0.914114  ...  0.995266  0.996554  0.982683   \n",
       "4815  0.983206  0.970264  0.885080  ...  0.984712  0.991678  0.941683   \n",
       "\n",
       "            14        15        16        17        18        19        20  \n",
       "0     0.999878  0.998156  0.020480  0.021457  0.059792  0.341579  0.055466  \n",
       "1     0.996183  0.987227  0.051334  0.046672  0.093138  0.368847  0.100020  \n",
       "2     0.977247  0.944809  0.088092  0.128199  0.186410  0.402511  0.162600  \n",
       "3     0.994137  0.981959  0.058319  0.098128  0.160436  0.401752  0.136039  \n",
       "4     0.977117  0.951324  0.092414  0.099082  0.151433  0.388351  0.129462  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4811  0.995888  0.980846  0.091893  0.072316  0.114093  0.389372  0.139226  \n",
       "4812  0.996118  0.981758  0.066331  0.100421  0.122299  0.380968  0.126737  \n",
       "4813  0.993824  0.990461  0.036137  0.040004  0.078104  0.355447  0.053794  \n",
       "4814  0.993867  0.983567  0.036973  0.063684  0.111289  0.389402  0.095167  \n",
       "4815  0.987410  0.964154  0.064336  0.085371  0.138990  0.377566  0.134740  \n",
       "\n",
       "[4816 rows x 21 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "added_m_data = []\n",
    "\n",
    "for i in range(to_generate):\n",
    "    reconstruction = model.sample(sampled_mu, sampled_logvar)\n",
    "    reconstruction = added_m_data.append(reconstruction[0].detach().cpu().numpy())\n",
    "\n",
    "col_name = [x for x in range(0, 21)]\n",
    "x_added = pd.DataFrame(added_m_data, columns=col_name)\n",
    "x_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4812</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4816 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1\n",
       "0     1  0\n",
       "1     1  0\n",
       "2     1  0\n",
       "3     1  0\n",
       "4     1  0\n",
       "...  .. ..\n",
       "4811  1  0\n",
       "4812  1  0\n",
       "4813  1  0\n",
       "4814  1  0\n",
       "4815  1  0\n",
       "\n",
       "[4816 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_name = [0, 1]\n",
    "\n",
    "y_targets = [[1, 0] for x in range(to_generate)]\n",
    "y_added = pd.DataFrame(y_targets, columns=col_name)\n",
    "\n",
    "y_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>0.510417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>0.108635</td>\n",
       "      <td>0.209030</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.173438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.108635</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.146875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>0.614583</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.186104</td>\n",
       "      <td>0.365741</td>\n",
       "      <td>0.180875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6768</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.097493</td>\n",
       "      <td>0.147157</td>\n",
       "      <td>0.287037</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>0.385417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.111978</td>\n",
       "      <td>0.182575</td>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.171984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>0.580733</td>\n",
       "      <td>0.830452</td>\n",
       "      <td>0.966683</td>\n",
       "      <td>0.981308</td>\n",
       "      <td>0.986558</td>\n",
       "      <td>0.966809</td>\n",
       "      <td>0.992561</td>\n",
       "      <td>0.966433</td>\n",
       "      <td>0.976364</td>\n",
       "      <td>0.843398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988135</td>\n",
       "      <td>0.995695</td>\n",
       "      <td>0.951360</td>\n",
       "      <td>0.995888</td>\n",
       "      <td>0.980846</td>\n",
       "      <td>0.091893</td>\n",
       "      <td>0.072316</td>\n",
       "      <td>0.114093</td>\n",
       "      <td>0.389372</td>\n",
       "      <td>0.139226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4812</th>\n",
       "      <td>0.549437</td>\n",
       "      <td>0.751886</td>\n",
       "      <td>0.956587</td>\n",
       "      <td>0.981358</td>\n",
       "      <td>0.984300</td>\n",
       "      <td>0.970934</td>\n",
       "      <td>0.994405</td>\n",
       "      <td>0.974678</td>\n",
       "      <td>0.967106</td>\n",
       "      <td>0.831706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993121</td>\n",
       "      <td>0.996327</td>\n",
       "      <td>0.964202</td>\n",
       "      <td>0.996118</td>\n",
       "      <td>0.981758</td>\n",
       "      <td>0.066331</td>\n",
       "      <td>0.100421</td>\n",
       "      <td>0.122299</td>\n",
       "      <td>0.380968</td>\n",
       "      <td>0.126737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>0.562664</td>\n",
       "      <td>0.824325</td>\n",
       "      <td>0.991001</td>\n",
       "      <td>0.994051</td>\n",
       "      <td>0.996786</td>\n",
       "      <td>0.982950</td>\n",
       "      <td>0.995018</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996481</td>\n",
       "      <td>0.882165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995603</td>\n",
       "      <td>0.997470</td>\n",
       "      <td>0.988606</td>\n",
       "      <td>0.993824</td>\n",
       "      <td>0.990461</td>\n",
       "      <td>0.036137</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.078104</td>\n",
       "      <td>0.355447</td>\n",
       "      <td>0.053794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>0.582847</td>\n",
       "      <td>0.789644</td>\n",
       "      <td>0.976714</td>\n",
       "      <td>0.995137</td>\n",
       "      <td>0.995449</td>\n",
       "      <td>0.980553</td>\n",
       "      <td>0.997388</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.988778</td>\n",
       "      <td>0.914114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995266</td>\n",
       "      <td>0.996554</td>\n",
       "      <td>0.982683</td>\n",
       "      <td>0.993867</td>\n",
       "      <td>0.983567</td>\n",
       "      <td>0.036973</td>\n",
       "      <td>0.063684</td>\n",
       "      <td>0.111289</td>\n",
       "      <td>0.389402</td>\n",
       "      <td>0.095167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>0.579723</td>\n",
       "      <td>0.794641</td>\n",
       "      <td>0.931766</td>\n",
       "      <td>0.981411</td>\n",
       "      <td>0.983284</td>\n",
       "      <td>0.955255</td>\n",
       "      <td>0.990775</td>\n",
       "      <td>0.983206</td>\n",
       "      <td>0.970264</td>\n",
       "      <td>0.885080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984712</td>\n",
       "      <td>0.991678</td>\n",
       "      <td>0.941683</td>\n",
       "      <td>0.987410</td>\n",
       "      <td>0.964154</td>\n",
       "      <td>0.064336</td>\n",
       "      <td>0.085371</td>\n",
       "      <td>0.138990</td>\n",
       "      <td>0.377566</td>\n",
       "      <td>0.134740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10488 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "2707  0.510417  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "5398  0.750000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "4281  0.614583  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "6768  0.656250  1.000000  0.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "2836  0.385417  0.000000  0.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4811  0.580733  0.830452  0.966683  0.981308  0.986558  0.966809  0.992561   \n",
       "4812  0.549437  0.751886  0.956587  0.981358  0.984300  0.970934  0.994405   \n",
       "4813  0.562664  0.824325  0.991001  0.994051  0.996786  0.982950  0.995018   \n",
       "4814  0.582847  0.789644  0.976714  0.995137  0.995449  0.980553  0.997388   \n",
       "4815  0.579723  0.794641  0.931766  0.981411  0.983284  0.955255  0.990775   \n",
       "\n",
       "            7         8         9   ...        11        12        13  \\\n",
       "2707  1.000000  1.000000  1.000000  ...  1.000000  1.000000  1.000000   \n",
       "5398  1.000000  1.000000  1.000000  ...  1.000000  1.000000  1.000000   \n",
       "4281  1.000000  1.000000  1.000000  ...  1.000000  1.000000  1.000000   \n",
       "6768  1.000000  1.000000  0.000000  ...  1.000000  1.000000  1.000000   \n",
       "2836  1.000000  1.000000  0.000000  ...  1.000000  1.000000  1.000000   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4811  0.966433  0.976364  0.843398  ...  0.988135  0.995695  0.951360   \n",
       "4812  0.974678  0.967106  0.831706  ...  0.993121  0.996327  0.964202   \n",
       "4813  0.996607  0.996481  0.882165  ...  0.995603  0.997470  0.988606   \n",
       "4814  0.996000  0.988778  0.914114  ...  0.995266  0.996554  0.982683   \n",
       "4815  0.983206  0.970264  0.885080  ...  0.984712  0.991678  0.941683   \n",
       "\n",
       "            14        15        16        17        18        19        20  \n",
       "2707  1.000000  1.000000  0.004340  0.108635  0.209030  0.444444  0.173438  \n",
       "5398  1.000000  1.000000  0.028302  0.108635  0.130435  0.305556  0.146875  \n",
       "4281  1.000000  1.000000  0.004377  0.109192  0.186104  0.365741  0.180875  \n",
       "6768  1.000000  1.000000  0.001057  0.097493  0.147157  0.287037  0.175000  \n",
       "2836  1.000000  1.000000  0.003566  0.111978  0.182575  0.379630  0.171984  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4811  0.995888  0.980846  0.091893  0.072316  0.114093  0.389372  0.139226  \n",
       "4812  0.996118  0.981758  0.066331  0.100421  0.122299  0.380968  0.126737  \n",
       "4813  0.993824  0.990461  0.036137  0.040004  0.078104  0.355447  0.053794  \n",
       "4814  0.993867  0.983567  0.036973  0.063684  0.111289  0.389402  0.095167  \n",
       "4815  0.987410  0.964154  0.064336  0.085371  0.138990  0.377566  0.134740  \n",
       "\n",
       "[10488 rows x 21 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_fab = pd.concat([x_fab, x_added])\n",
    "x_fab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6768</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4812</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10488 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1\n",
       "2707  0  1\n",
       "5398  1  0\n",
       "4281  0  1\n",
       "6768  0  1\n",
       "2836  0  1\n",
       "...  .. ..\n",
       "4811  1  0\n",
       "4812  1  0\n",
       "4813  1  0\n",
       "4814  1  0\n",
       "4815  1  0\n",
       "\n",
       "[10488 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fab = pd.concat([y_raw, y_added])\n",
    "y_fab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw = torch.Tensor(x_raw.values)\n",
    "x_fab = torch.Tensor(x_fab.values)\n",
    "x_test = torch.Tensor(x_test.values)\n",
    "\n",
    "y_raw = torch.Tensor(y_raw.values)\n",
    "y_fab = torch.Tensor(y_fab.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        self.hidden_layer_1 = nn.Linear(self.in_dim, 10)\n",
    "        self.hidden_layer_2 = nn.Linear(10, 2)\n",
    "        self.output_layer = nn.Linear(2, self.out_dim)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layer_1(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.hidden_layer_2(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        # x = self.hidden_layer_3(x)\n",
    "        # x = self.activation(x)\n",
    "        \n",
    "        y = self.output_layer(x)\n",
    "        y = self.activation(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10488, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork(21, 2)\n",
    "\n",
    "# Test structure of model\n",
    "predictions = model.forward(x_fab)\n",
    "\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset to treat how the model picks an x, y combination from the dataset\n",
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    # Requires you to return data as a pair of _x, _y\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(loader, model, optimizer, loss_fn, batch_size):\n",
    "    loop = tqdm(loader)\n",
    "    \n",
    "    count = 0\n",
    "    ave_loss = 0.00\n",
    "    \n",
    "    # Loop per batch\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        predictions = model.forward(data)\n",
    "        \n",
    "        loss = loss_fn(predictions, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "        ave_loss += loss.item()\n",
    "        count += 1\n",
    "        \n",
    "    ave_loss = ave_loss / count\n",
    "    \n",
    "    return ave_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = MyCustomDataset(x=x_fab, y=y_fab)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    custom_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 556.30it/s, loss=0.0253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.1737750083371443\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 474.93it/s, loss=0.0208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.18381108531907728\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 423.08it/s, loss=0.0174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.1694989370464483\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 412.50it/s, loss=0.014] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.1502049157739545\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 415.52it/s, loss=0.0109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.12692911828955986\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 424.22it/s, loss=0.0083] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.106061109017183\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 405.76it/s, loss=0.00618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.08823002954666193\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 421.21it/s, loss=0.00443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.0723898887866886\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 429.21it/s, loss=0.00301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.05638036400901404\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 410.73it/s, loss=0.00206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.04505267977564497\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 429.58it/s, loss=0.00149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.03847624330674418\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 435.66it/s, loss=0.00114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.03444551154756936\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 440.60it/s, loss=0.000926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.032124231788788114\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 471.60it/s, loss=0.000771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.030464971456139592\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 461.90it/s, loss=0.000661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.029170845908905646\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 444.61it/s, loss=0.000577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.028085383334625146\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 413.64it/s, loss=0.000509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.027090496725182038\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 427.90it/s, loss=0.000455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.026163189217508827\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 413.55it/s, loss=0.000413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.02533828573907593\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 425.50it/s, loss=0.00038] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.02460442622388301\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 421.23it/s, loss=0.000353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.023935779498388314\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 428.21it/s, loss=0.000332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.02332358694553569\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 425.45it/s, loss=0.000314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.022777783783063697\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 420.37it/s, loss=0.000297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.02230233573983329\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 436.64it/s, loss=0.000283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.02188423929184294\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 428.82it/s, loss=0.00027] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.021506694827193383\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 442.85it/s, loss=0.000258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.02115520802005845\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 430.53it/s, loss=0.000247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.020817827710319616\n",
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 442.29it/s, loss=0.000237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.020485104728151966\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 437.42it/s, loss=0.000227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.020148389781244416\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 448.95it/s, loss=0.000218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.019797125065510793\n",
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 430.99it/s, loss=0.000209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.01942417901707924\n",
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 449.41it/s, loss=0.000199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.01903328131624996\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 423.71it/s, loss=0.000189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.018632617601611053\n",
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 434.34it/s, loss=0.000178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.01822590557755555\n",
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 440.60it/s, loss=0.000166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.017812372053304753\n",
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 429.63it/s, loss=0.000154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.017390429886481547\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 437.99it/s, loss=0.000142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.016960908379952646\n",
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 433.68it/s, loss=0.000129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.016528538563642038\n",
      "Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 427.32it/s, loss=0.000117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.016100226974492163\n",
      "Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 409.99it/s, loss=0.000105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.015683296144950724\n",
      "Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 411.10it/s, loss=9.34e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.01528499303925954\n",
      "Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 409.54it/s, loss=8.28e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.014911106002082125\n",
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 419.87it/s, loss=7.31e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.014563746690426089\n",
      "Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 402.76it/s, loss=6.45e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.014240624208874272\n",
      "Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 447.44it/s, loss=5.68e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.013938026637103921\n",
      "Epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 414.47it/s, loss=4.99e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.013653519197497762\n",
      "Epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 419.86it/s, loss=4.39e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.013385767060872352\n",
      "Epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 483.93it/s, loss=3.85e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.013133994901756117\n",
      "Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 500.75it/s, loss=3.38e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.012897858344500825\n",
      "Epoch: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 561.58it/s, loss=2.97e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.012677238178504706\n",
      "Epoch: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 533.31it/s, loss=2.62e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.012471909979350408\n",
      "Epoch: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 541.92it/s, loss=2.3e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.012281459436512276\n",
      "Epoch: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 549.10it/s, loss=2.03e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.01210527436841879\n",
      "Epoch: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 550.53it/s, loss=1.8e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011942563877961632\n",
      "Epoch: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 536.46it/s, loss=1.6e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011792336154741801\n",
      "Epoch: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 562.49it/s, loss=1.42e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011653427751047296\n",
      "Epoch: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 539.73it/s, loss=1.27e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011524533253332464\n",
      "Epoch: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 551.92it/s, loss=1.13e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011404332392708754\n",
      "Epoch: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 554.62it/s, loss=1.02e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011291618184264914\n",
      "Epoch: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 538.16it/s, loss=9.16e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.01118540648588806\n",
      "Epoch: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 556.79it/s, loss=8.28e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011084934143404297\n",
      "Epoch: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 558.57it/s, loss=7.5e-6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010989614902509826\n",
      "Epoch: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 545.98it/s, loss=6.81e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010898991854977476\n",
      "Epoch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 555.72it/s, loss=6.2e-6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.01081269700464795\n",
      "Epoch: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 507.15it/s, loss=5.66e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010730417807805767\n",
      "Epoch: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 521.06it/s, loss=5.18e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010651894034773375\n",
      "Epoch: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 560.49it/s, loss=4.76e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010576902274113493\n",
      "Epoch: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 532.06it/s, loss=4.37e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010505227897963971\n",
      "Epoch: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 547.42it/s, loss=4.03e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010436710089520412\n",
      "Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 529.32it/s, loss=3.72e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010371182949657594\n",
      "Epoch: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 554.61it/s, loss=3.44e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010308490154965565\n",
      "Epoch: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 554.40it/s, loss=3.19e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010248483478875876\n",
      "Epoch: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 537.32it/s, loss=2.96e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010191026560036636\n",
      "Epoch: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 556.94it/s, loss=2.76e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010135987941311663\n",
      "Epoch: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 539.73it/s, loss=2.57e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010083234032403859\n",
      "Epoch: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 531.40it/s, loss=2.4e-6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.010032634622367614\n",
      "Epoch: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 546.86it/s, loss=2.24e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009984064883736253\n",
      "Epoch: 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 565.88it/s, loss=2.1e-6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009937401008932034\n",
      "Epoch: 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 537.20it/s, loss=1.97e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009892531728910766\n",
      "Epoch: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 553.66it/s, loss=1.85e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009849339973308818\n",
      "Epoch: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 555.78it/s, loss=1.74e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009807726758880336\n",
      "Epoch: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 566.44it/s, loss=1.64e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009767589715965868\n",
      "Epoch: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 605.30it/s, loss=1.55e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009728837223759912\n",
      "Epoch: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 592.27it/s, loss=1.46e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009691381424736573\n",
      "Epoch: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 505.61it/s, loss=1.38e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009655150042522098\n",
      "Epoch: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 433.79it/s, loss=1.31e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.00962007154795424\n",
      "Epoch: 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 462.10it/s, loss=1.24e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009586084686500513\n",
      "Epoch: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 406.29it/s, loss=1.17e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009553137155857825\n",
      "Epoch: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 400.19it/s, loss=1.11e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009521177614369008\n",
      "Epoch: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 417.06it/s, loss=1.06e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.00949016871865077\n",
      "Epoch: 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:05<00:00, 398.93it/s, loss=1.01e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009460069633289249\n",
      "Epoch: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 521.55it/s, loss=9.56e-7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009430848692052945\n",
      "Epoch: 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 479.94it/s, loss=9.11e-7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.00940246977537438\n",
      "Epoch: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 516.97it/s, loss=8.67e-7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.00937490240893056\n",
      "Epoch: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:04<00:00, 483.39it/s, loss=8.27e-7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009348106969804208\n",
      "Epoch: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 539.44it/s, loss=7.89e-7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009322044654099252\n",
      "Epoch: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 539.40it/s, loss=7.52e-7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009296673148804765\n",
      "Epoch: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 549.39it/s, loss=7.18e-7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009271942120095418\n",
      "Epoch: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2098/2098 [00:03<00:00, 536.41it/s, loss=6.86e-7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.009247799397110706\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    \n",
    "    ave_loss = train_nn(\n",
    "        train_loader,\n",
    "        model,\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "        batch_size\n",
    "    )\n",
    "    \n",
    "    losses.append(ave_loss)\n",
    "    \n",
    "    print(\"Ave Loss: {}\".format(ave_loss))\n",
    "    \n",
    "    state = { 'state_dict': model.state_dict() }\n",
    "\n",
    "    # acc: 0.90832, f1: 0.78\n",
    "    # torch.save(state, \"annthyroid_model.pth\")\n",
    "    \n",
    "    torch.save(state, \"annthyroid_model2.pth\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses, label='loss', color='red')\n",
    "plt.title('Training Evaluation', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Error Value', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.forward(x_test)\n",
    "predictions = predictions.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1418, 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reverse_ohe(preds):\n",
    "    ohe = []\n",
    "    \n",
    "    for i in preds:\n",
    "        if i[0] > i[1]:\n",
    "            ohe.append([1, 0])\n",
    "        else:\n",
    "            ohe.append([0, 1])\n",
    "        \n",
    "    return ohe\n",
    "\n",
    "preds = reverse_ohe(predictions)\n",
    "preds = np.array(preds)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9083215796897038\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}'.format(accuracy_score(preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.43      0.60       229\n",
      "           1       0.90      1.00      0.95      1189\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1418\n",
      "   macro avg       0.95      0.72      0.78      1418\n",
      "weighted avg       0.92      0.91      0.89      1418\n",
      " samples avg       0.91      0.91      0.91      1418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(preds, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae03ce6f38b86b61e05d3f0e4339342b058157d9f0092e90d0a518f5ecf9e2f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
